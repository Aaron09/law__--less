Variance and standard deviation Suppose you are to be given a payment, with the size ofthe payment, in some unit of money, given by either X or by Y, described as follows. The randomvariable X is equal to 100 with probability one, whereas pY 100000 = 11000 and pY 0 = 9991000 .Would you be equally happy with either payment? Both X and Y have mean 100. This exampleillustrates that two random variables with quite dierent pmfs can have the same mean. The pmffor X is concentrated on the mean value, while the pmf for Y is considerably spread out.The variance of a random variable X is a measure of how spread out the pmf of X is. LettingX = EX, the variance is dened by:VarX = EX  X 2.2.4The dierence X  X is called the deviation of X from its mean. The deviation is the error ifX is predicted by X . By linearity of expectation, the mean of the deviation is zero: EX  X  =EX  X = X  X = 0. Sometimes VarX is called the mean square deviation of X, becauseIt might seem a little arbitrary that variance isit is the mean of the square of the deviation.dened using a power of two, rather than some other power, such as four.It does make senseto talk about the mean fourth power deviation, EX  X 4, or the mean absolute deviation,E|X  X|. However, the mean square deviation has several important mathematical properties2.2. THE MEAN AND VARIANCE OF A RANDOM VARIABLE31which facilitate computation, so it is by far the most commonly used measure of how spread outa distribution is. The variance of X is often denoted by 2standard deviation of X. If X is in some units, then X is in the same units. For example. if X isin feet, then VarX is in feet2 and X is again in feet.X , where X =cid:112VarX is called theAs mentioned earlier, the variance of X is a measure of how spread out the pmf of X is. If aconstant b is added to X, the pmf of the resulting random variable X + b is obtained by shifting thepmf of X by b. Adding the constant increases the mean by b, but it does not change the variance,because variance measures spread around the mean. Indeed, by the linearity of expectation, 2.3:EX + b = EX + bVarX + b = EX + b  EX + b2 = EX + b  EX  b2 = EX  EX2 = VarX.If X is multiplied by a constant a, the pmf of the resulting random variable is spread out by afactor a. The mean is multiplied by a, and the variance is multiplied by a2 :EaX = aEXVaraX = EaX  EaX2 = EaX  aEX2 = a2EX  EX2 = a2VarX.Combining the two observations just made yields that:EaX + b = aEX + b and VaraX + b = VaraX = a2VarX.The random variable XXvariable has mean zero and variance one:is called the standardized version of X. The standardized randomXEcid:20 X  Xcid:18 X  XXcid:21cid:19XVar==1X12XEX  X  = 0EX  X 2 =2X2X= 1.Note that even if X is a measurement in some units such as meters, the standardized randomvariable XXis dimensionless, because the standard deviation X is in the same units as X.XUsing the linearity of expectation, we derive another expression for VarX :VarX = EX 2  2X X + 2X = EX 2  2X EX + 2= EX 2  2X .X2.5For an integer i  1, the ith moment of X is dened to be EX i. Therefore, the variance of arandom variable is equal to its second moment minus the square of its rst moment. The denitionof variance, 2.4, is useful for keeping in mind the meaning and scaling properties of variance,while the equivalent expression 2.5 is often more useful for computing the variance of a randomvariable from its distribution.32CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLES2.3 Conditional probabilitiesLet A and B be two events for some probability experiment. The conditional probability of B givenA is dened bycid:40 P ABP B|A =P Aif P A > 0undened if P A = 0.It is not dened if P A = 0, which has the following meaning. If you were to write a computerroutine to compute P B|A and the inputs are P AB = 0 and P A = 0, your routine shouldntsimply return the value zero. Rather, your routine should generate an error message such as inputerrorconditioning on event of probability zero. Such an error message would help you or othersnd errors in larger computer programs which use the routine.Intuitively, if you know that event A is true for a probability experiment, then you know thatthe outcome  of the probability experiment is in A. Conditioned on that, whether B is also trueshould only depend on the outcomes in B that are also in A, which is the set AB. If B is equalto A, then, given A is true, B should be true with conditional probability one. That is why thedenition of P B|A has P A in the denominator.One of the very nice things about elementary probability theory is the simplicity of this deni-tion of conditional probability. Sometimes we might get conicting answers when calculating theprobability of some event, using two dierent intuitive methods. When that happens, inevitably,at least one of the methods has a aw in it, and falling back on simple denitions such as thedenition of conditional probability clears up the conict, and sharpens our intuition.The following examples show that the coVariance and standard deviation Suppose you are to be given a payment, with the size ofthe payment, in some unit of money, given by either X or by Y, described as follows. The randomvariable X is equal to 100 with probability one, whereas pY 100000 = 11000 and pY 0 = 9991000 .Would you be equally happy with either payment? Both X and Y have mean 100. This exampleillustrates that two random variables with quite dierent pmfs can have the same mean. The pmffor X is concentrated on the mean value, while the pmf for Y is considerably spread out.The variance of a random variable X is a measure of how spread out the pmf of X is. LettingX = EX, the variance is dened by:VarX = EX  X 2.2.4The dierence X  X is called the deviation of X from its mean. The deviation is the error ifX is predicted by X . By linearity of expectation, the mean of the deviation is zero: EX  X  =EX  X = X  X = 0. Sometimes VarX is called the mean square deviation of X, becauseIt might seem a little arbitrary that variance isit is the mean of the square of the deviation.dened using a power of two, rather than some other power, such as four.It does make senseto talk about the mean fourth power deviation, EX  X 4, or the mean absolute deviation,E|X  X|. However, the mean square deviation has several important mathematical properties2.2. THE MEAN AND VARIANCE OF A RANDOM VARIABLE31which facilitate computation, so it is by far the most commonly used measure of how spread outa distribution is. The variance of X is often denoted by 2standard deviation of X. If X is in some units, then X is in the same units. For example. if X isin feet, then VarX is in feet2 and X is again in feet.X , where X =cid:112VarX is called theAs mentioned earlier, the variance of X is a measure of how spread out the pmf of X is. If aconstant b is added to X, the pmf of the resulting random variable X + b is obtained by shifting thepmf of X by b. Adding the constant increases the mean by b, but it does not change the variance,because variance measures spread around the mean. Indeed, by the linearity of expectation, 2.3:EX + b = EX + bVarX + b = EX + b  EX + b2 = EX + b  EX  b2 = EX  EX2 = VarX.If X is multiplied by a constant a, the pmf of the resulting random variable is spread out by afactor a. The mean is multiplied by a, and the variance is multiplied by a2 :EaX = aEXVaraX = EaX  EaX2 = EaX  aEX2 = a2EX  EX2 = a2VarX.Combining the two observations just made yields that:EaX + b = aEX + b and VaraX + b = VaraX = a2VarX.The random variable XXvariable has mean zero and variance one:is called the standardized version of X. The standardized randomXEcid:20 X  Xcid:18 X  XXcid:21cid:19XVar==1X12XEX  X  = 0EX  X 2 =2X2X= 1.Note that even if X is a measurement in some units such as meters, the standardized randomvariable XXis dimensionless, because the standard deviation X is in the same units as X.XUsing the linearity of expectation, we derive another expression for VarX :VarX = EX 2  2X X + 2X = EX 2  2X EX + 2= EX 2  2X .X2.5For an integer i  1, the ith moment of X is dened to be EX i. Therefore, the variance of arandom variable is equal to its second moment minus the square of its rst moment. The denitionof variance, 2.4, is useful for keeping in mind the meaning and scaling properties of variance,while the equivalent expression 2.5 is often more useful for computing the variance of a randomvariable from its distribution.32CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLES2.3 Conditional probabilitiesLet A and B be two events for some probability experiment. The conditional probability of B givenA is dened bycid:40 P ABP B|A =P Aif P A > 0undened if P A = 0.It is not dened if P A = 0, which has the following meaning. If you were to write a computerroutine to compute P B|A and the inputs are P AB = 0 and P A = 0, your routine shouldntsimply return the value zero. Rather, your routine should generate an error message such as inputerrorconditioning on event of probability zero. Such an error message would help you or othersnd errors in larger computer programs which use the routine.Intuitively, if you know that event A is true for a probability experiment, then you know thatthe outcome  of the probability experiment is in A. Conditioned on that, whether B is also trueshould only depend on the outcomes in B that are also in A, which is the set AB. If B is equalto A, then, given A is true, B should be true with conditional probability one. That is why thedenition of P B|A has P A in the denominator.One of the very nice things about elementary probability theory is the simplicity of this deni-tion of conditional probability. Sometimes we might get conicting answers when calculating theprobability of some event, using two dierent intuitive methods. When that happens, inevitably,at least one of the methods has a aw in it, and falling back on simple denitions such as thedenition of conditional probability clears up the conict, and sharpens our intuition.The following examples show that the co