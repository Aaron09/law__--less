ts a, b, c, d. The variance of the sum of uncorrelated random variables is equal to thesum of the variances of the random variables. For example, if X and Y are uncorrelated,VarX + Y  = CovX + Y, X + Y  = CovX, X + CovY, Y  + 2CovX, Y  = VarX + VarY ,and this calculation extends to three or more random variables4.8. CORRELATION AND COVARIANCE197For example, consider the sum Sn = X1 +  + Xn, such that X1, , Xn are uncorrelated soCovXi, Xj = 0 if i cid:54= j with EXi =  and VarXi = 2 for 1  i  n. ThenESn = n4.24andVarSn = CovSn, Sn = CovXjncid:88j=1Xi, ncid:88cid:88i=1i,j:icid:54=jncid:88i=1ncid:88ncid:88ncid:88i=1===CovXi, Xjj=1CovXi, Xi +CovXi, XjVarXi + 0 = n2.4.25Therefore, the standardized version of Sn is the random variable Snnn2 .i=1Example 4.8.1 Identify the mean and variance of a a binomial random variable with parametersn and p, b a negative binomial random variable with parameters r and p, and c an Erlang randomvariable with parameters r and .Solution:a A binomial random variable with parameters n and p has the form S = X1 + . . . +Xn, where X1, . . . , Xn are independent Bernoulli random variables with parameter p. So EXi = pfor each i, VarXi = p1  p, and, since the Xis are independent, they are uncorrelated. Thus,by 4.24 and 4.25, ES = np and VarS = np1  p.b Similarly, as seen in Section 2.6, a negative binomial random variable, Sr, with parameters r andp, arises as the sum of r independent geometrically distributed random variables with parameterp. Each such geometric random variable has mean 1/p and variance 1  p/p2. So, ESr = rp andVarSr = r1pc Likewise, as seen in Section 3.5, an Erlang random variable, Tr, with parameters r and ,arises as the sum of r independent exponentially distributed random variables with parameter .An exponentially distributed random variable with parameter  has mean 1/ and variance 1/2.Therefore, ETr = r and VarTr = r2 .p2..Example 4.8.2 Simplify the following expressions:a Cov8X + 3, 5Y  2, b Cov10X  5,3X + 15, c CovX+2,10X-3Y, d 10X,Y +4.198CHAPTER 4. JOINTLY DISTRIBUTED RANDOM VARIABLESSolution a Cov8X + 3, 5Y  2 = Cov8X, 5Y  = 40CovX, Y .b Cov10X  5,3X + 15 = Cov10X,3X = 30CovX, X = 30VarX.c CovX+2,10X-3Y=CovX,10X-3Y=10CovX,X-3CovX,Y=10VarX-3CovX,Y.d Since Cov10X, Y +4 = 10CovX, Y , the standard deviation of 10X is 10X , and the standarddeviation of Y + 4 is Y , 10X,Y +4 = 10CovX,Y 10X Y= CovX,Y = X,Y .X YIt is clear from the denition that the correlation coecient X,Y is a scaled version of CovX, Y .The units that EXY  or CovX, Y  are measured in are the product of the units that X is mea-sured in times the units that Y is measured in. For example, if X is in kilometers and Y is inseconds, then CovX, Y  is in kilometer-seconds. If we were to change units of the rst variable tometers, then X in kilometers would be changed to 1000X in meters, and the covariance betweenthe new measurement in meters and Y would be Cov1000X, Y  = 1000CovX, Y , which would bemeasured in meter-seconds. In contrast, the correlation coecient X,Y is dimensionlessit carriesno units. That is because the units of the denominator, X Y , in the denition of X,Y , are theunits of X times the units of Y, which are also the units of the numerator, CovX, Y . The situationis similar to the use of the standardized versions of random variables X and Y , namely XEXand Y EY . These standardized versions have mean zero, variance one, and are dimensionless. Infact, the covariance between the standardized versions of X and Y is X,Y :XYcid:18 X  EXXCovY  EY Y,cid:19cid:18 Xcid:19= Cov,YYX=CovX, Y X Y= X,Y .If the units of X or Y are changed by linear or ane scaling, such as changing from kilometers tometers, or degrees C to degrees F the correlation coecient does not change:aX+b,cY +d = X,Yfor a, c > 0.In a sense, therefore, the correlation coecient X,Y is the standardized version of the covariance,CovX, Y , or of the correlation, EXY . As shown in the corollary of the following proposition,correlation coecients are always in the interval 1, 1. As shown in Section 4.9, covariance orcorrelation coecients play a central role for estimating Y by a linear function of X. Positivecorrelation i.e. X,Y > 0 means that X and Y both tend to be large or both tend to be small,whereas a negative correlation i.e. X,Y < 0 means that X and Y tend to be opposites: if X islarger than average it tends to indicate that Y is smaller than average. The extreme case X,Y = 1means Y can be perfectly predicted by a linear function aX + b with a > 0, and the extremecase X,Y = 1 means Y can be perfectly predicted by a linear function aX + b with a < 0. Asmentioned earlier in this section, X and Y are said to be uncorrelated if CovX, Y  = 0, and beinguncorrelated does not imply independence.Proposition 4.8.3 Schwarzs inequality For two random variables X and Y :Furthermore, if EX 2 cid:54= 0, equality holds in 4.26 i.e. |EXY | =cid:112EX 2EY 2 if and only ifEX 2EY 2.4.26|EXY |  cid:112PY = cX = 1 for some constant c.4.8. CORRELATION AN