d:26 1  c200  c  2c  2.P L  c|B = 1  P L  c|B =Since L has the Exp0.1 distribution if Bc is true, P L  c|Bc = ec/10 for all c  0.Combining these facts and using P B = P Bc = 12 , yieldscid:26 12 1  cP L  c =P L  5 + 3|L  5 =1c  22 + ec/10 0  c  22 ec/102 e0.82 e0.5= e0.3 = 0.7408116.1A shorter answer is the following. Given L  5, the radio must be from the secondbatch, and thus have an exponentially distributed lifetime with parameter . By thememoryless property of the exponential distribution, the radio after ve years is as gooda new. So the probability it lasts at least three more years is e3 = e0.3.b By the denition of conditional probabilities and 6.1,2 e0.42 + e0.1P L  1 + 3|L  1 =2  111= 0.47713.12. Disk crashes modeled by a Poisson processa The duration of time times the rate per unit time is 24.b The number of crashes in a ve hour period has the Poisson distribution with mean 5,so the probability of exactly three crashes in a ve hour period is 53e5.3!c The mean time until a disk crash is 1 , so the mean time until three disk crashes is 3 .d The time of the third disk crash has the Erlang distribution with parameters  andcid:26 3t2et20t  0else.r = 3, so the pdf is fT t =3.14. Poisson tweetsa The number of tweets in one week is a Poisson random variable with parameter 1/77 =1. Let Wi be the event you receive exactly one tweet on week i. Then P Wi =e111/1! = e1, and by the independence of non-overlapping intervals, P W1, W2, W3, W4 =P W1P W2P W3P W4 =cid:0e1cid:14 = e4.with parameter 1/714 = 2. Then, PT > 2 = PN2  2 = cid:802b Let T be the time in weeks until the third tweet arrives, and let N2 be the numberof tweets received by the end of the second week, which is a Poisson random variablek=0 e22k/k! =e220/0! + e221/1! + e222/2! = 5e2.c The time between consecutive tweets has the exponential distribution with parameter1/7, and thus mean 7 days. By the memoryless property of the exponential distribution,the mean amount of additional time until the arrival of the fth tweet is 7 5 = 35 days,or ve weeks.6.6. SOLUTIONS TO EVEN NUMBERED PROBLEMS263Linear Scaling, Gaussian Distribution, ML Parameter EstimationSections 3.6  3.73.16. Gaussian distributiona Since X is a continuous-type random variable, PX = c = 0 for any c, including c = 0.bP|X + 4|  2 = PX  6 or X  2distribution is symmetric about -4= 2P= 2Q2/3.= PX  6 + PX  2= 2PX  2cid:26 X + 4cid:26 X + 43cid:27 2 + 4cid:27 6 + 4333cid:19cid:18 23cid:18 2cid:19.3Note that we could get the same answer without using the symmetry property:PX  6 = P= = QcdP0 < X < 2 = PX > 0  PX  2 Pcid:26 X + 4cid:27= P> 4/3= Q4/3  Q2.3cid:26 X + 43cid:27 2We remark that in the above solution we could have written  instead of > and/or> instead of , because X is a continuous type random variable.PX 2 < 9 = P3 < X < 3X + 4cid:26 1cid:27<= P= Q1/3  Q7/3.33< 7/33.18. Blind guessing answers on an exama By the problem description we take X to have the binomial distribution with parametersn = 10 and p = 0.5. Since S = 3X  310  X = 6X  30,PS  12 = P6X  30  12 = PX  7.Since EX = 5, the Markov inequality yields:PS  12 = PX  7  EX7=57.264CHAPTER 6. APPENDIXb By the observed symmetry and the connection to X,PS  12 = 0.5P|S|  12 = 0.5P|X  5|  2.Since EX = 5 and VarX = 100.50.5 = 52 , Chebyshev inequality yieldsPS  12 = 0.5P|X  5|  2  VarX2  4=516.cPS  12 = PX  7 = PX  6.5 = Pcid:26 X  52.5cid:27 Qcid:19cid:18 1.52.5 1.52.5= 0.1714.3.20. Betting with doubling or halvinga If he wins a game, his money increases by a factor of 32 . If he loses a game, his moneydecreases by a factor of 2. By denition, he wins X games and loses 196  X games inthe rst 196 games. Thus, his money after 196 games iscid:18 3cid:19Xcid:18 1cid:19196X22= 21763X .S = 220b From part a,PS  1 = Plog2 S  0 = P176+X log23  0 = Pcid:19Since EX = 98 and VarX = 49,cid:18 X  98cid:18 12cid:19PS  1 = P 110  9877 7= 1  QX  176log23cid:18 12cid:197= 0.9568.cid:26cid:27= PX  110.Using the continuity correction as follows gives a more accurate estimate. To derive it,note that PX  110 = PX  110.5 because X is integer valued, and approximatePX  110.5 :cid:18 X  98cid:19cid:18 12.5cid:19 110.5  98 cid:18 12.5cid:19= 1  QPS  1 = P= 0.9629.Using the binomial distribution directly gives PS  1 = PX  110 = 0.9631.77773.22. ML parameter estimation for Rayleigh and uniform distributionsa By denition, cid:98M L10 is the value of  that maximizes the likelihood of X = 10. Thelikelihood of X = 10 is f10 =cid:0 10 = 50, and it is positive for  < 50 and negative for  > 50. Hence, cid:98M L10 = 50.reasoning as above shows that, in general, for observation X = u,cid:98M L = cid:1002M L = u2Note: If  is replaced by 2, then f is the Rayleigh pdf with parameter 2. The same2 .2 , and the log likelihood is ln10  ln  50 .2 . This derivative is zero forDierentiation with respect to  yields d ln f10cid:1 e 100=  1 + 50db The pdf of Y is given byfau =cid:40 12a 1a0= a if 1a  u  2aelseIn order for fa3 > 0, the support of fa must include the observed value u