nditional probability of an event can be smaller than,larger than, or equal to, the unconditional probability of the event. Here, the phrase unconditionalprobability of the event is the same as the probability of the event; the word unconditional isused just to increase the contrast with conditional probability.Example 2.3.1 Roll two dice and observe the numbers coming up. Dene two events by: A=thesum is six, and B=the numbers are not equal. Find and compare P B and P B|A.Solution: The sample space is  = i, j : 1  i  6, 1  j  6, which has 36 equally likelyevents. To nd P B we count the number of outcomes in B. There are six choices for the numbercoming up on the rst die, and for each of those, ve choices for the number coming up on thesecond die that is dierent from the rst. So B has 6 5 = 30 outcomes, and P B = 30/36 = 5/6.Another way to see that P B = 5/6 is to notice that whatever the number on the rst die is, theprobability that the number on the second die will be dierent from it is 5/6.AB = 1, 5, 2, 4, 4, 2, 5, 1 we have P AB = 4/36.Since A = 1, 5, 2, 4, 3, 3, 4, 2, 5, 1 we have P A = 5/36. Similarly, sinceTherefore, P B|A = P ABP A = 4/365/36 = 45 . Note that, for this example, P B|A < P B. Thatis, if one learns that the sum is six, the chances that dierent numbers show on the dice decreasesfrom the original probability that dierent numbers show on the dice.2.3. CONDITIONAL PROBABILITIES33Example 2.3.2 Continuing with the previous example, nd and compare P Bc and P Bc|A.6 . Since ABc = 3, 3, P ABc = 1Solution: Here, Bc is the event that the numbers coming up are the same. Since six outcomesare in Bc, P Bc = 636 = 136 . As noted above, P A = 5/36.5/36 = 1/5. Another way to compute P Bc|A would have been toTherefore, P Bc|A = P ABcnotice that P B|A+P Bc|A = 1, and use the fact, from Example 2.3.1, that P B|A = 4/5. Notethat, for this example, P Bc|A > P Bc. That is, if one learns that the sum is six, the chancesthat the numbers coming up are the same number increases from the original probability that thenumbers coming up are the same.P A = 1/36Example 2.3.3 Again, consider the rolls of two fair dice. Let E=the number showing on therst die is even, and F =the sum of the numbers showing is seven. Find and compare P F  andP F|E.12 . Since E has 18 outcomes, P E = 16 . Since EF = 2, 5, 4, 3, 6, 1, P EF  =Solution: Since F has six outcomes, P F  = 636 = 136 . Note that,for this example, P F  = P F|E. That is, if one learns that the number coming up on the rstdie is even, the conditional probability that the numbers coming up on the dice sum to seven is thesame as the original probability that the numbers sum to seven.2 . Therefore, P F|E = P EF 36 = 1P E = 1/121/2 = 1We comment briey on some properties of conditional probabilities. These properties followeasily from the denition of conditional probabilities, and the axioms of probability. Suppose A isan event with P A > 0, and B and C are also events. Then1. P B|A  0.2. P B|A+P Bc|A = 1. More generally, if E1, E2, . . . are disjoint events, P E1E2|B =P E1|B + P E2|B +  .3. P |B = 1.4. P AB = P AP B|A.5. P ABC = P CP B|CP A|BC assuming P BC > 0.The rst three properties above are equivalent to the statement that, as a function of the argu-ment B for A xed, the conditional probability P B|A has all the properties of an unconditionalprobability measure P. Compare these properties to the probability axioms in Section 1.2. Intu-itively, if one assumes a probability distribution P is given, and then later learns that an event Ais true, the conditional probabilities P B|A as B varies, is a new probability distribution, givinga new view of the experiment modeled by the probability space.34CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLES2.4 Independence and the binomial distribution2.4.1 Mutually independent eventsLet A and B be two events for some probability space. Consider rst the case that P A > 0.As seen in the previous section, it can be that P B|A = P B, which intuitively means thatIt is then natural toknowledge that A is true does not aect the probability that B is true.consider the events to be independent. If P B|A cid:54= P B, then knowledge that A is true doesaect the probability that B is true, and it is natural to consider the events to be dependenti.e. not independent. Since, by denition, P B|A = P ABP A , the condition P B|A = P B isequivalent to P AB = P AP B.Lets consider the other case: P A = 0. Should we consider A and B to be independent? Itdoesnt make sense to condition on A, but P Ac = 1, so we can consider P B|Ac instead. It holdsP Ac = P AcB = P B  P AB = P B. Therefore, P B|Ac = P B. Thatthat P B|Ac = P AcBis, if P A = 0, knowledge that A is not true does not aect the probability of B. So it is naturalto consider A to be independent of B.These observations motivate the following denition, which has the advantage of applyingwhether or not P A = 0 :Denition 2.4.1 Event A is independent of event B if P AB = P AP B.Note that the condition in the dennditional probability of an event can be smaller than,larger than, or equal to, the unconditional probability of the event. Here, the phrase unconditionalprobability of the event is the same as the probability of the event; the word unconditional isused just to increase the contrast with conditional probability.Example 2.3.1 Roll two dice and observe the numbers coming up. Dene two events by: A=thesum is six, and B=the numbers are not equal. Find and compare P B and P B|A.Solution: The sample space is  = i, j : 1  i  6, 1  j  6, which has 36 equally likelyevents. To nd P B we count the number of outcomes in B. There are six choices for the numbercoming up on the rst die, and for each of those, ve choices for the number coming up on thesecond die that is dierent from the rst. So B has 6 5 = 30 outcomes, and P B = 30/36 = 5/6.Another way to see that P B = 5/6 is to notice that whatever the number on the rst die is, theprobability that the number on the second die will be dierent from it is 5/6.AB = 1, 5, 2, 4, 4, 2, 5, 1 we have P AB = 4/36.Since A = 1, 5, 2, 4, 3, 3, 4, 2, 5, 1 we have P A = 5/36. Similarly, sinceTherefore, P B|A = P ABP A = 4/365/36 = 45 . Note that, for this example, P B|A < P B. Thatis, if one learns that the sum is six, the chances that dierent numbers show on the dice decreasesfrom the original probability that dierent numbers show on the dice.2.3. CONDITIONAL PROBABILITIES33Example 2.3.2 Continuing with the previous example, nd and compare P Bc and P Bc|A.6 . Since ABc = 3, 3, P ABc = 1Solution: Here, Bc is the event that the numbers coming up are the same. Since six outcomesare in Bc, P Bc = 636 = 136 . As noted above, P A = 5/36.5/36 = 1/5. Another way to compute P Bc|A would have been toTherefore, P Bc|A = P ABcnotice that P B|A+P Bc|A = 1, and use the fact, from Example 2.3.1, that P B|A = 4/5. Notethat, for this example, P Bc|A > P Bc. That is, if one learns that the sum is six, the chancesthat the numbers coming up are the same number increases from the original probability that thenumbers coming up are the same.P A = 1/36Example 2.3.3 Again, consider the rolls of two fair dice. Let E=the number showing on therst die is even, and F =the sum of the numbers showing is seven. Find and compare P F  andP F|E.12 . Since E has 18 outcomes, P E = 16 . Since EF = 2, 5, 4, 3, 6, 1, P EF  =Solution: Since F has six outcomes, P F  = 636 = 136 . Note that,for this example, P F  = P F|E. That is, if one learns that the number coming up on the rstdie is even, the conditional probability that the numbers coming up on the dice sum to seven is thesame as the original probability that the numbers sum to seven.2 . Therefore, P F|E = P EF 36 = 1P E = 1/121/2 = 1We comment briey on some properties of conditional probabilities. These properties followeasily from the denition of conditional probabilities, and the axioms of probability. Suppose A isan event with P A > 0, and B and C are also events. Then1. P B|A  0.2. P B|A+P Bc|A = 1. More generally, if E1, E2, . . . are disjoint events, P E1E2|B =P E1|B + P E2|B +  .3. P |B = 1.4. P AB = P AP B|A.5. P ABC = P CP B|CP A|BC assuming P BC > 0.The rst three properties above are equivalent to the statement that, as a function of the argu-ment B for A xed, the conditional probability P B|A has all the properties of an unconditionalprobability measure P. Compare these properties to the probability axioms in Section 1.2. Intu-itively, if one assumes a probability distribution P is given, and then later learns that an event Ais true, the conditional probabilities P B|A as B varies, is a new probability distribution, givinga new view of the experiment modeled by the probability space.34CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLES2.4 Independence and the binomial distribution2.4.1 Mutually independent eventsLet A and B be two events for some probability space. Consider rst the case that P A > 0.As seen in the previous section, it can be that P B|A = P B, which intuitively means thatIt is then natural toknowledge that A is true does not aect the probability that B is true.consider the events to be independent. If P B|A cid:54= P B, then knowledge that A is true doesaect the probability that B is true, and it is natural to consider the events to be dependenti.e. not independent. Since, by denition, P B|A = P ABP A , the condition P B|A = P B isequivalent to P AB = P AP B.Lets consider the other case: P A = 0. Should we consider A and B to be independent? Itdoesnt make sense to condition on A, but P Ac = 1, so we can consider P B|Ac instead. It holdsP Ac = P AcB = P B  P AB = P B. Therefore, P B|Ac = P B. Thatthat P B|Ac = P AcBis, if P A = 0, knowledge that A is not true does not aect the probability of B. So it is naturalto consider A to be independent of B.These observations motivate the following denition, which has the advantage of applyingwhether or not P A = 0 :Denition 2.4.1 Event A is independent of event B if P AB = P AP B.Note that the condition in the den