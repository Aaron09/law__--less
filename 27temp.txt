mf of X. The mean of X can be calculated using the law of total probability:EX = EX|AP A + EX|AcP Ac=np2+nq2=np + q2=n2.2.10. THE LAW OF TOTAL PROBABILITY, AND BAYES FORMULA59To calculate VarX we will use the fact VarX = EX 2  EX2, and apply the law of totalprobability:EX 2 = EX 2|AP A + EX 2|AcP Ac.Here EX 2|A is the second moment of the binomial distribution with parameters n and p, whichis equal to the mean squared plus the variance: EX 2|A = np2 + npq. Similarly, EX 2|Ac =nq2 + nqp. Therefore,EX 2 =np2 + npq2+nq2 + nqp2=n2p2 + q22+ npq,soNote thatVarX = EX 2  EX2 14+ np1  p.cid:18 p2 + q2cid:192cid:18 n1  2p= n2cid:19+ npq=22X =cid:112VarX  1  2pn,random variable with parameters n and p iscid:112np1  p, which is proportional towhich for xed p grows linearly with n. In comparison, the standard deviation for a binomialn.260CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLES2.11 Binary hypothesis testing with discrete-type observationsThe basic framework for binary hypothesis testing is illustrated in Figure 2.11. It is assumed thatFigure 2.11: The framework for binary hypothesis testing.either hypothesis H1 is true or hypothesis H0 is true, as indicated by the position of the switch atthe left end of the gure. Based on which hypothesis is true, a system generates an observationX. The observation is fed into a decision rule, which then declares either H1 or H0. The system isassumed to be random, so the decision rule can sometimes declare the true hypothesis, or it canmake an error and declare the other hypothesis. For example, the data could be from a computeraided tomography CAT scan system, and the hypotheses could be H1 : a tumor is present; H0 : notumor is present. Here we model the observed data by a discrete-type random variable X. Supposeif hypothesis H1 is true, then X has pmf p1 and if hypothesis H0 is true then X has pmf p0. Thelikelihood matrix is an array with one row for each of the two hypotheses, and one column for eachpossible value of X. The entries in the row for hypothesis Hi are values of the corresponding pmf,pi. For example, the likelihood matrix might be the following:X = 0 X = 1 X = 2 X = 3H1H00.00.40.10.30.30.20.60.1In practice, the numbers in the table might be based on data accumulated from past experimentswhen either one or the other hypothesis is known to be true. As mentioned above, a decisionrule species, for each possible observation, which hypothesis is declared. A decision rule canbe conveniently displayed on the likelihood matrix by underlining one entry in each column, tospecifying which hypothesis is to be declared for each possible value of X. An example of a decisionrule is shown below, where H1 is declared whenever X  1. For example, if X = 2 is observed,then H1 is declared, because the entry underlined under X = 2 is in the H1 row of the likelihoodmatrix.X = 0 X = 1 X = 2 X = 3H1H00.00.40.10.30.30.20.60.1underlines indicatethe decision ruleused for this example.Since there are two possibilities for which hypothesis is true, and two possibilities for which hy-pothesis is declared, there are four possible outcomes:Hypothesis H0 is true and H0 is declared.Hypothesis H1 is true and H1 is declared.systemXHHH  or H0110decision rule2.11. BINARY HYPOTHESIS TESTING WITH DISCRETE-TYPE OBSERVATIONS61Hypothesis H0 is true and H1 is declared. This is called a false alarm.2Hypothesis H1 is true and H0 is declared. This is called a miss.By convention, pfalse alarm is dened to be the conditional probability:pfalse alarm = P declare H1 true |H0.Note that pfalse alarm is the sum of the entries in the H0 row of the likelihood matrix that are notunderlined. For the decision rule given above pfalse alarm = P declare H1 true |H0 = 0.3+0.2+0.1 =0.6. Note that pfalse alarm is rather large for this rule.A similar analysis can be carried out for the case when H1 is the true hypothesis and we declarethat H0 is the true hypothesis. By convention, pmiss is dened to be the conditional probability:pmiss = P declare H0 true |H1.Note that pmiss is the sum of the entries of the H1 row of the likelihood matrix that are notunderlined. The decision rule above declares H1 unless X = 0, and P X = 0|H1 = 0.0. Thereforepmiss = 0.0, which is unusually good. Of course this small value pmiss is earned at the expense of thelarge value of pfalse alarm noted above.It is important to keep in mind the convention that both pfalse alarm and pmiss are dened asconditional probabilities.Any decision rule can be indicated by underlining one element in each column of the likelihoodmatrix. For a given rule, pmiss is the sum of entries not underlined in the H1 row of the likelihoodmatrix, and pfalse alarm is the sum of the entries not underlined in the H0 row of the likelihood matrix.This representation allows us to illustrate trade-os between the two types of error probabilities. Ifthe underlining in some column is moved from one row to the other, then one error probability in-creases because there is one more entry not underlinmf of X. The mean of X can be calculated using the law of total probability:EX = EX|AP A + EX|AcP Ac=np2+nq2=np + q2=n2.2.10. THE LAW OF TOTAL PROBABILITY, AND BAYES FORMULA59To calculate VarX we will use the fact VarX = EX 2  EX2, and apply the law of totalprobability:EX 2 = EX 2|AP A + EX 2|AcP Ac.Here EX 2|A is the second moment of the binomial distribution with parameters n and p, whichis equal to the mean squared plus the variance: EX 2|A = np2 + npq. Similarly, EX 2|Ac =nq2 + nqp. Therefore,EX 2 =np2 + npq2+nq2 + nqp2=n2p2 + q22+ npq,soNote thatVarX = EX 2  EX2 14+ np1  p.cid:18 p2 + q2cid:192cid:18 n1  2p= n2cid:19+ npq=22X =cid:112VarX  1  2pn,random variable with parameters n and p iscid:112np1  p, which is proportional towhich for xed p grows linearly with n. In comparison, the standard deviation for a binomialn.260CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLES2.11 Binary hypothesis testing with discrete-type observationsThe basic framework for binary hypothesis testing is illustrated in Figure 2.11. It is assumed thatFigure 2.11: The framework for binary hypothesis testing.either hypothesis H1 is true or hypothesis H0 is true, as indicated by the position of the switch atthe left end of the gure. Based on which hypothesis is true, a system generates an observationX. The observation is fed into a decision rule, which then declares either H1 or H0. The system isassumed to be random, so the decision rule can sometimes declare the true hypothesis, or it canmake an error and declare the other hypothesis. For example, the data could be from a computeraided tomography CAT scan system, and the hypotheses could be H1 : a tumor is present; H0 : notumor is present. Here we model the observed data by a discrete-type random variable X. Supposeif hypothesis H1 is true, then X has pmf p1 and if hypothesis H0 is true then X has pmf p0. Thelikelihood matrix is an array with one row for each of the two hypotheses, and one column for eachpossible value of X. The entries in the row for hypothesis Hi are values of the corresponding pmf,pi. For example, the likelihood matrix might be the following:X = 0 X = 1 X = 2 X = 3H1H00.00.40.10.30.30.20.60.1In practice, the numbers in the table might be based on data accumulated from past experimentswhen either one or the other hypothesis is known to be true. As mentioned above, a decisionrule species, for each possible observation, which hypothesis is declared. A decision rule canbe conveniently displayed on the likelihood matrix by underlining one entry in each column, tospecifying which hypothesis is to be declared for each possible value of X. An example of a decisionrule is shown below, where H1 is declared whenever X  1. For example, if X = 2 is observed,then H1 is declared, because the entry underlined under X = 2 is in the H1 row of the likelihoodmatrix.X = 0 X = 1 X = 2 X = 3H1H00.00.40.10.30.30.20.60.1underlines indicatethe decision ruleused for this example.Since there are two possibilities for which hypothesis is true, and two possibilities for which hy-pothesis is declared, there are four possible outcomes:Hypothesis H0 is true and H0 is declared.Hypothesis H1 is true and H1 is declared.systemXHHH  or H0110decision rule2.11. BINARY HYPOTHESIS TESTING WITH DISCRETE-TYPE OBSERVATIONS61Hypothesis H0 is true and H1 is declared. This is called a false alarm.2Hypothesis H1 is true and H0 is declared. This is called a miss.By convention, pfalse alarm is dened to be the conditional probability:pfalse alarm = P declare H1 true |H0.Note that pfalse alarm is the sum of the entries in the H0 row of the likelihood matrix that are notunderlined. For the decision rule given above pfalse alarm = P declare H1 true |H0 = 0.3+0.2+0.1 =0.6. Note that pfalse alarm is rather large for this rule.A similar analysis can be carried out for the case when H1 is the true hypothesis and we declarethat H0 is the true hypothesis. By convention, pmiss is dened to be the conditional probability:pmiss = P declare H0 true |H1.Note that pmiss is the sum of the entries of the H1 row of the likelihood matrix that are notunderlined. The decision rule above declares H1 unless X = 0, and P X = 0|H1 = 0.0. Thereforepmiss = 0.0, which is unusually good. Of course this small value pmiss is earned at the expense of thelarge value of pfalse alarm noted above.It is important to keep in mind the convention that both pfalse alarm and pmiss are dened asconditional probabilities.Any decision rule can be indicated by underlining one element in each column of the likelihoodmatrix. For a given rule, pmiss is the sum of entries not underlined in the H1 row of the likelihoodmatrix, and pfalse alarm is the sum of the entries not underlined in the H0 row of the likelihood matrix.This representation allows us to illustrate trade-os between the two types of error probabilities. Ifthe underlining in some column is moved from one row to the other, then one error probability in-creases because there is one more entry not underlin