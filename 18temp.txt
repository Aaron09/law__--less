 independence, and the nal one: P ABC =P AP BP C.Finally, we give a denition of independence for any nite collection of events, which generalizesthe above denitions for independence of two or three events.Denition 2.4.7 Events A1, A2, . . . , An are independent ifP Ai1Ai2  Aik  = P Ai1P Ai2 P Aik whenever 2  k  n and 1  i1 < i2 <  < ik  n.The denition of independence is strong enough that if new events are made by set operations onnonoverlapping subsets of the original events, then the new events are also independent. That is,suppose A1, A2, . . . , An are independent events, suppose n = n1 ++nk with ni  1 for each i, andsuppose B1 is dened by Boolean operations intersections, complements, and unions of the rst n1events A1, . . . , An1, B2 is dened by Boolean operations on the next n2 events, An1+1, . . . , An1+n2,and so on, then B1, . . . , Bk are independent.Independent random variables of discrete-type2.4.2Denition 2.4.8 Random variables X and Y are independent if any event of the form X  A isindependent of any event of the form Y  B.If X and Y are independent random variables and i and j are real values, thenPX = i, Y = j = pX ipY j this follows by taking A = i and B = j in the denition ofindependence. Conversely, if X and Y are discrete-type random variables such that2.4.INDEPENDENCE AND THE BINOMIAL DISTRIBUTION37PX = i, Y = j = pX ipY j for all i, j, then for any subsets A and B of the real numbers,PX  A, Y  B ==cid:88cid:32cid:88iAi,j:iA,jBcid:33cid:88jBpX ipY jPX = i, Y = j =cid:88cid:88iAjBpX ipY j = PX  APY  B,so that X  A and Y  B are mutually independent events. Thus, discrete random variablesX and Y are independent if and only if PX = i, Y = j = pX ipY j for all i, j,More generally, random variables not necessarily discrete-type X1, X2, . . . , Xn are mutuallyindependent if any set of events of the form X1  A1,X2  A2, . . . ,Xn  An are mutuallyindependent. Independence of random variables is discussed in more detail in Section 4.4.2.4.3 Bernoulli distributionSome distributions arise so frequently that they have names. Two such distributions are discussedin this section: the Bernoulli and binomial distributions. The geometric and Poisson distributionsare two other important discrete-type distributions with names, and they are introduced in latersections.A random variable X is said to have the Bernoulli distribution with parameter p, where 0  p 1, if PX = 1 = p and PX = 0 = 1p. Note that EX = p. Since X = X 2, EX 2 = EX = p.So VarX = EX 2  EX2 = p  p2 = p1  p. The variance is plotted as a function of p inFigure 2.4. It is symmetric about 1/2, and achieves its maximum value, 1/4, at p = 1/2.Figure 2.4: The variance of a Bernoulli random variable versus p.38CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLES2.4.4 Binomial distributionSuppose n independent Bernoulli trials are conducted, each resulting in a one with probability pand a zero with probability 1  p. Let X denote the total number of ones occurring in the n trials.Any particular outcome with k ones and n  k zeros, such as 11010101, if n = 8 and k = 5, hascid:1 such outcomes, we nd that the pmf of X isprobability pk1  pnk. Since there arecid:0ncid:19cid:18nkpk1  pnkfor 0  k  n.pX k =kThe distribution of X is called the binomial distribution with parameters n and p. Figure 2.5 showsthe binomial pmf for n = 24 and p = 1/3. Since a partition for the sample space  is the set ofFigure 2.5: The pmf of a binomial random variable with n = 24 and p = 1/3.n + 1 events of the form X = k for 0  k  n, it follows from the axioms of probability that thepmf pX just derived sums to one. We will double check that fact using a series expansion. Recallthat the Taylor series expansion of a function f about a point xo is given byf x = f xo + fcid:48xox  xo + fcid:48cid:48xox  xo22+ fcid:48cid:48cid:48xox  xo33!+  .The Maclaurin series expansion of a function f is the Taylor series expansion about xo = 0 :f x = f 0 + fcid:480x + fcid:48cid:480+ fcid:48cid:48cid:480The Maclaurin series expansion of f x = 1 + xn is given byx22cid:18ncid:19ncid:88kk=01 + xn =xk.+  .x33!2.62.4.INDEPENDENCE AND THE BINOMIAL DISTRIBUTION39Substituting x = p/1  p into 2.6 and multiplying through by 1  pn yields thatcid:18ncid:19ncid:88kk=0pk1  pnk = 1,so the binomial pmf sums to one, as expected.Since each trial results in a one with probability p, and there are n trials, the mean number ofones is given by EX = np. This same result can be derived with more work from the pmf:EX ==cid:19cid:19kkk=0cid:18nncid:88cid:18nncid:88ncid:88n1cid:88k=1k=1kkpk1  pnkpk1  pnkn  1!n  k!k  1!cid:18n  1cid:19= nppk11  pnk= npll=0pl1  pn1lhere l = k  12.7The variance of the binomial distribution is given by VarX = np1  p. This fact can be shownusing the pmf, but a simpler derivation is given in Example 4.8.1.= np.To explore the shape of the pmf, we examine the ratio of consecutive terms:pkpk  1==pk1  pnkn!k!nk!n!k1!nk+1! pk11  pnk+1n  k + 1pk1  p.Therefore, pk  pk  1 if and only if n  k + 1p  k1  p, or equiva