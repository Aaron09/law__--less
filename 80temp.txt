D COVARIANCEProof. Take  = EXY /EX 2 and note that0  EY  X2 = EY 2  2EXY  + 2EX 2= EY 2  EXY 2EX 2,1994.27which implies that EXY 2  EX 2EY 2, which is equivalent to the Schwarz inequality.IfPY = cX = 1 for some c then equality holds in 4.26, and conversely, if equality holds in4.26 then equality also holds in 4.27, so EY  X2 = 0, and therefore PY = cX = 1 forc = .Corollary 4.8.4 For two random variables X and Y,|CovX, Y |  cid:112VarXVarY .Furthermore, if VarX cid:54= 0 then equality holds if and only if Y = aX + b for some constants aand b. Consequently, if VarX and VarY  are not zero, so the correlation coecient X,Y is welldened, then |X,Y |  1, X,Y = 1 if and only if Y = aX + b for some a, b with a > 0, and X,Y = 1 if and only if Y = aX + b for some a, b with a < 0.Proof. The corollary follows by applying the Schwarz inequality to the random variables X  EXand Y  EY . is X1X2X3 5 2 02 5 20 2 5 .Example 4.8.5 Suppose the covariance matrix of a random vectorHere, the ijth entry of the matrix, meaning the ith from the top and jth from the left, is CovXi, Xj.For example, CovX1, X2 = 2.a Find CovX1 + X2, X1 + X3.b Find a so that X2  aX1 is uncorrelated with X1.c Find the correlation coecient, X1,X2d Find VarX1 + X2 + X3.Solution: Let ci,j = CovXi, Xj. ThenCovX1 + X2, X1 + X3 = c1,1 + c1,3 + c2,1 + c2,3 = 5 + 0 + 2 + 2 = 9.b CovX2  aX1, X1 = c2,1  ac1,1 = 2  5a, which is zero for a = 25 .c VarXi = CovXi, Xi = 5 for all i and CovX1, X2 = 2.So X1,X2 = 255d VarX1 + X2 + X3 = Covcid:803i=1 Xi,cid:803= 25 .sum of all entries in the covariance matrix.j=1 Xj = 23, because the covariance expands out to the200CHAPTER 4. JOINTLY DISTRIBUTED RANDOM VARIABLESExample 4.8.6 Suppose n fair dice are independently rolled. Letcid:26 1 if one shows on the kth diek=1 Xk, which is the number of ones showing, and Y =cid:80n0 else.0 elseYk =Xk =Let X =cid:80ncid:26 1 if two shows on the kth diek=1 Yk, which is the numberof twos showing. Note that if a histogram is made recording the number of occurrences of each ofthe six numbers, then X and Y are the heights of the rst two entries in the histogram.a Find EX1 and VarX1.b Find EX and VarX.c Find CovXi, Yj if 1  i  n and 1  j  n Hint: Does it make a dierence if i = j?d Find CovX, Y .e Find the correlation coecient X,Y . Are X and Y positively correlated, uncorrelated, or neg-atively correlated?Solution a Each Xk is a Bernoulli random variable with parameter p = 1VarXk = EX 2b EX = nEX1 = nc If i cid:54= j then CovXi, Xj = 0, because Xi and Yj are associated with dierent, independent,dice rolls. If i = j the situation is dierent. The joint pmf of Xi and Yi for any i is:k   EXk2 = p  p2 = p1  p = 536 .6 , and VarX = nVarX1 = 5n36 .6 , so EXk = 16 andpXi,Yi1, 0 =16pXi,Yi0, 1 =16pXi,Yi0, 0 =46.In particular, XiYi is always equal to zero, because it is not possible for both a one and a two to showon a single roll of the die. Thus, EXiYi = 0. Therefore, CovXi, Yi = EXiYi  EXiEYi =0  1d Using the answer to part c yields36 . Not surprisingly, Xi and Yi are negatively correlated.6 =  116CovX, Y  = CovXi,Yjncid:88j=1cid:88i,j:icid:54=jCovXi, Yj ncid:88ncid:88i=1j=1cid:18cid:19i=1ncid:88ncid:88ncid:88i=1i=1===CovXi, Yi +CovXi, Yj 136+ 0 =  n36.4.8. CORRELATION AND COVARIANCE201e Using the denition of correlation coecient and answers to b and d yields:X,Y = n36cid:113 5n5n3636=  15.Since CovX, Y  < 0, or, equivalently, X,Y < 0, X and Y are negatively correlated. This makessense; if X is larger than average, it means that there were more ones showing than average, whichwould imply that there should be somewhat fewer twos showing than average.Example 4.8.7 Suppose X1, . . . , Xn are independent and identically distributed random variables,with mean  and variance 2. It might be that the mean and variance are unknown, and that thedistribution is not even known to be a particular type, so maximum likelihood estimation is notappropriate. In this case it is reasonable to estimate  and 2 by the sample mean and samplevariance dened as follows:cid:98X =1nncid:88k=1Xk cid:992 =1n  1ncid:88Xk  cid:98X2.k=1Note the perhaps unexpected appearance of n  1 in the sample variance. Of course, we shouldhave n  2 to estimate the variance assuming we dont know the mean so it is not surprising thatthe formula is not dened if n = 1. An estimator is called unbiased if the mean of the estimator isequal to the parameter that is being estimated. a Is the sample mean an unbiased estimator of? b Find the mean square error, E  cid:98X2, for estimation of the mean by the sample mean.c Is the sample variance an unbiased estimator of 2?ncid:88Solution a By the linearity of expectation,ncid:88Ecid:98X =so cid:98X is an unbiased estimator of .b The mean square error for estimating  by cid:98X is given byncid:88E  cid:98X2 = Varcid:98X =cid:32 ncid:88EXk =Xk=cid:331nk=1k=11n1n2 Vark=1 = ,1n2VarXk =ncid:88k=11n22 =2n.ccid:104cid:992cid:105Encid:88k=1=1n  1EXk  cid:98X2 =EX1  cid:98X2,k=1nn  1202because, by symmetry, EXk  cid:98X2 D COVARIANCEProof. Take  = EXY /EX 2 and note that0  EY  X2 = EY 2  2EXY  + 2EX 2= EY 2  EXY 2EX 2,1994.27which implies that EXY 2  EX 2EY 2, which is equivalent to the Schwarz inequality.IfPY = cX = 1 for some c then equality holds in 4.26, and conversely, if equality holds in4.26 then equality also holds in 4.27, so EY  X2 = 0, and therefore PY = cX = 1 forc = .Corollary 4.8.4 For two random variables X and Y,|CovX, Y |  cid:112VarXVarY .Furthermore, if VarX cid:54= 0 then equality holds if and only if Y = aX + b for some constants aand b. Consequently, if VarX and VarY  are not zero, so the correlation coecient X,Y is welldened, then |X,Y |  1, X,Y = 1 if and only if Y = aX + b for some a, b with a > 0, and X,Y = 1 if and only if Y = aX + b for some a, b with a < 0.Proof. The corollary follows by applying the Schwarz inequality to the random variables X  EXand Y  EY . is X1X2X3 5 2 02 5 20 2 5 .Example 4.8.5 Suppose the covariance matrix of a random vectorHere, the ijth entry of the matrix, meaning the ith from the top and jth from the left, is CovXi, Xj.For example, CovX1, X2 = 2.a Find CovX1 + X2, X1 + X3.b Find a so that X2  aX1 is uncorrelated with X1.c Find the correlation coecient, X1,X2d Find VarX1 + X2 + X3.Solution: Let ci,j = CovXi, Xj. ThenCovX1 + X2, X1 + X3 = c1,1 + c1,3 + c2,1 + c2,3 = 5 + 0 + 2 + 2 = 9.b CovX2  aX1, X1 = c2,1  ac1,1 = 2  5a, which is zero for a = 25 .c VarXi = CovXi, Xi = 5 for all i and CovX1, X2 = 2.So X1,X2 = 255d VarX1 + X2 + X3 = Covcid:803i=1 Xi,cid:803= 25 .sum of all entries in the covariance matrix.j=1 Xj = 23, because the covariance expands out to the200CHAPTER 4. JOINTLY DISTRIBUTED RANDOM VARIABLESExample 4.8.6 Suppose n fair dice are independently rolled. Letcid:26 1 if one shows on the kth diek=1 Xk, which is the number of ones showing, and Y =cid:80n0 else.0 elseYk =Xk =Let X =cid:80ncid:26 1 if two shows on the kth diek=1 Yk, which is the numberof twos showing. Note that if a histogram is made recording the number of occurrences of each ofthe six numbers, then X and Y are the heights of the rst two entries in the histogram.a Find EX1 and VarX1.b Find EX and VarX.c Find CovXi, Yj if 1  i  n and 1  j  n Hint: Does it make a dierence if i = j?d Find CovX, Y .e Find the correlation coecient X,Y . Are X and Y positively correlated, uncorrelated, or neg-atively correlated?Solution a Each Xk is a Bernoulli random variable with parameter p = 1VarXk = EX 2b EX = nEX1 = nc If i cid:54= j then CovXi, Xj = 0, because Xi and Yj are associated with dierent, independent,dice rolls. If i = j the situation is dierent. The joint pmf of Xi and Yi for any i is:k   EXk2 = p  p2 = p1  p = 536 .6 , and VarX = nVarX1 = 5n36 .6 , so EXk = 16 andpXi,Yi1, 0 =16pXi,Yi0, 1 =16pXi,Yi0, 0 =46.In particular, XiYi is always equal to zero, because it is not possible for both a one and a two to showon a single roll of the die. Thus, EXiYi = 0. Therefore, CovXi, Yi = EXiYi  EXiEYi =0  1d Using the answer to part c yields36 . Not surprisingly, Xi and Yi are negatively correlated.6 =  116CovX, Y  = CovXi,Yjncid:88j=1cid:88i,j:icid:54=jCovXi, Yj ncid:88ncid:88i=1j=1cid:18cid:19i=1ncid:88ncid:88ncid:88i=1i=1===CovXi, Yi +CovXi, Yj 136+ 0 =  n36.4.8. CORRELATION AND COVARIANCE201e Using the denition of correlation coecient and answers to b and d yields:X,Y = n36cid:113 5n5n3636=  15.Since CovX, Y  < 0, or, equivalently, X,Y < 0, X and Y are negatively correlated. This makessense; if X is larger than average, it means that there were more ones showing than average, whichwould imply that there should be somewhat fewer twos showing than average.Example 4.8.7 Suppose X1, . . . , Xn are independent and identically distributed random variables,with mean  and variance 2. It might be that the mean and variance are unknown, and that thedistribution is not even known to be a particular type, so maximum likelihood estimation is notappropriate. In this case it is reasonable to estimate  and 2 by the sample mean and samplevariance dened as follows:cid:98X =1nncid:88k=1Xk cid:992 =1n  1ncid:88Xk  cid:98X2.k=1Note the perhaps unexpected appearance of n  1 in the sample variance. Of course, we shouldhave n  2 to estimate the variance assuming we dont know the mean so it is not surprising thatthe formula is not dened if n = 1. An estimator is called unbiased if the mean of the estimator isequal to the parameter that is being estimated. a Is the sample mean an unbiased estimator of? b Find the mean square error, E  cid:98X2, for estimation of the mean by the sample mean.c Is the sample variance an unbiased estimator of 2?ncid:88Solution a By the linearity of expectation,ncid:88Ecid:98X =so cid:98X is an unbiased estimator of .b The mean square error for estimating  by cid:98X is given byncid:88E  cid:98X2 = Varcid:98X =cid:32 ncid:88EXk =Xk=cid:331nk=1k=11n1n2 Vark=1 = ,1n2VarXk =ncid:88k=11n22 =2n.ccid:104cid:992cid:105Encid:88k=1=1n  1EXk  cid:98X2 =EX1  cid:98X2,k=1nn  1202because, by symmetry, EXk  cid:98X2 