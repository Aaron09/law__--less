tric distribution with parameter p. Let L2 denote the number of trials, afterthe rst L1 trials, until again the outcome of a trial is one. Then L2 also has the geometricdistribution with parameter p. In general, let Lj denote the number of trials needed after the rstL1 +  + Lj1 trials, until again the outcome of a trial is one. The random variables L1, L2, . . .are independent random variables, each geometrically distributed with parameter p. Note that theLs are determined by the Xs. The converse is also true; the values of all the Ls determine thevalues of all the Xs.We shall give two more ways to describe the process. Let Sj denote the total number oftrials, counting from the very rst one, until a total of j trials have outcome one. Equivalently,Sj = L1 + L2 +  Lj, for j  1. The Ls determine the Ss, and the converse is also true:Lj = Sj  Sj1 for j  1, with the understanding S0 = 0.Let Ck denote the cumulative number of ones in the rst k trials. That is, Ck = X1 + X2 + +Xk. By convention, C0 = 0. The sequence Ck : k  0 is sometimes called the counting sequence ofthe Bernoulli process, because it counts the number of ones vs. the number of trials. Clearly, thecounting sequence is determined by the Xs. Conversely, the Xs are determined by the countingsequence: Xk = Ck  Ck1 for k  0. If 0  k  l, the dierence Cl  Ck is called the incrementof C over the interval k, l = k + 1, k + 2, , l. It is the number of trials in the interval withoutcome equal to one.To summarize, there are four ways to describe the same random sequence: The underlying Bernoulli sequence X1, X2, . . .. The random variables X1, X2, are inde-pendent Bernoulli random variables with parameter p. The numbers of additional trials required for each successive one to be observed: L1, L2, .The random variables L1, L2, are independent, geometrically distributed random variableswith parameter p.310203040501k02L1L2L3S1SS3XsCs22.7. THE POISSON DISTRIBUTIONA LIMIT OF BINOMIAL DISTRIBUTIONS45 The cumulative number of ones in k trials, for k  0, C0, C1, C2, . . .. For k xed, Ck is thenumber of ones in k independent Bernoulli trials, so it has the binomial distribution withparameters k and p. More generally, for 0  k < l, the increment Cl  Ck is the number ofones in l  k Bernoulli trials, so it has the binomial distribution with parameters l  k and p.Also, the increments of C over nonoverlapping intervals are independent. The cumulative numbers of trials for j ones, for j  0: S0, S1, S2, . . .. As discussed below,for integers r  1, Sr has the negative binomial distribution with parameters r and p.Negative binomial distribution In the remainder of this section we discuss the distributionof Sr, which is the number of trials required for r ones, for r  1. The possible values of Sr arer, r + 1, r + 2, . . . . So let n  r, and let k = n r. The event Sr = n is determined by the outcomesof the rst n trials. The event is true if and only if there are r  1 ones and k zeros in the rstprobability pr11  pnrp. Therefore, the pmf of Sr is given byk + r  1 trials, and trial n is a one. There are cid:0n1cid:1 such sequences of length n, and each hasr1pn =pr1  pnrfor n  r.cid:18n  1cid:19r  11  xr =cid:88k=0This is called the negative binomial distribution with parameters r and p. To check that the pmfsums to one, begin with the Maclaurin series expansion i.e. Taylor series expansion about zeroof 1  xr :Set x = 1  p and use the change of variables k = n  r to get:cid:18n  1cid:19r  1cid:88n=rpr1  pnr = prxk.cid:19r  1cid:18k + r  1cid:18k + r  1cid:88r  1k=0cid:191  pk = 1.Use of the expansion of 1 xr here, in analogy to the expansion of 1 + xn used for the binomialdistribution, explains the name negative binomial distribution. Since Sr = L1 + . . . Lr, whereeach Lj has mean 1p . It is shown in Example 4.8.1 that VarSr = rVarL1 = r1pp , ESr = r.p22.7 The Poisson distributiona limit of binomial distributionsk!By denition, the Poisson probability distribution with parameter  > 0 is the one with pmffor k  0. In particular, 0! is dened to equal one, so p0 = e. The next threepk = ekterms of the pmf are p1 = e, p2 = 26 e. The Poisson distributionarises frequently in practice, because it is a good approximation for a binomial distribution withparameters n and p, when n is very large, p is very small, and  = np. Some examples in whichsuch binomial distributions occur are:2 e, and p3 = 346CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLES Radio active emissions in a xed time interval: n is the number of uranium atoms in arock sample, and p is the probability that any particular one of those atoms emits a particlein a one minute period. Incoming phone calls in a xed time interval: n is the number of people with cellphones within the access region of one base station, and p is the probability that a given suchperson will make a call within the next minute. Misspelled words in a document: n is the number of words in a document and p is theprobability that a given word is misspelled.Binomial dtric distribution with parameter p. Let L2 denote the number of trials, afterthe rst L1 trials, until again the outcome of a trial is one. Then L2 also has the geometricdistribution with parameter p. In general, let Lj denote the number of trials needed after the rstL1 +  + Lj1 trials, until again the outcome of a trial is one. The random variables L1, L2, . . .are independent random variables, each geometrically distributed with parameter p. Note that theLs are determined by the Xs. The converse is also true; the values of all the Ls determine thevalues of all the Xs.We shall give two more ways to describe the process. Let Sj denote the total number oftrials, counting from the very rst one, until a total of j trials have outcome one. Equivalently,Sj = L1 + L2 +  Lj, for j  1. The Ls determine the Ss, and the converse is also true:Lj = Sj  Sj1 for j  1, with the understanding S0 = 0.Let Ck denote the cumulative number of ones in the rst k trials. That is, Ck = X1 + X2 + +Xk. By convention, C0 = 0. The sequence Ck : k  0 is sometimes called the counting sequence ofthe Bernoulli process, because it counts the number of ones vs. the number of trials. Clearly, thecounting sequence is determined by the Xs. Conversely, the Xs are determined by the countingsequence: Xk = Ck  Ck1 for k  0. If 0  k  l, the dierence Cl  Ck is called the incrementof C over the interval k, l = k + 1, k + 2, , l. It is the number of trials in the interval withoutcome equal to one.To summarize, there are four ways to describe the same random sequence: The underlying Bernoulli sequence X1, X2, . . .. The random variables X1, X2, are inde-pendent Bernoulli random variables with parameter p. The numbers of additional trials required for each successive one to be observed: L1, L2, .The random variables L1, L2, are independent, geometrically distributed random variableswith parameter p.310203040501k02L1L2L3S1SS3XsCs22.7. THE POISSON DISTRIBUTIONA LIMIT OF BINOMIAL DISTRIBUTIONS45 The cumulative number of ones in k trials, for k  0, C0, C1, C2, . . .. For k xed, Ck is thenumber of ones in k independent Bernoulli trials, so it has the binomial distribution withparameters k and p. More generally, for 0  k < l, the increment Cl  Ck is the number ofones in l  k Bernoulli trials, so it has the binomial distribution with parameters l  k and p.Also, the increments of C over nonoverlapping intervals are independent. The cumulative numbers of trials for j ones, for j  0: S0, S1, S2, . . .. As discussed below,for integers r  1, Sr has the negative binomial distribution with parameters r and p.Negative binomial distribution In the remainder of this section we discuss the distributionof Sr, which is the number of trials required for r ones, for r  1. The possible values of Sr arer, r + 1, r + 2, . . . . So let n  r, and let k = n r. The event Sr = n is determined by the outcomesof the rst n trials. The event is true if and only if there are r  1 ones and k zeros in the rstprobability pr11  pnrp. Therefore, the pmf of Sr is given byk + r  1 trials, and trial n is a one. There are cid:0n1cid:1 such sequences of length n, and each hasr1pn =pr1  pnrfor n  r.cid:18n  1cid:19r  11  xr =cid:88k=0This is called the negative binomial distribution with parameters r and p. To check that the pmfsums to one, begin with the Maclaurin series expansion i.e. Taylor series expansion about zeroof 1  xr :Set x = 1  p and use the change of variables k = n  r to get:cid:18n  1cid:19r  1cid:88n=rpr1  pnr = prxk.cid:19r  1cid:18k + r  1cid:18k + r  1cid:88r  1k=0cid:191  pk = 1.Use of the expansion of 1 xr here, in analogy to the expansion of 1 + xn used for the binomialdistribution, explains the name negative binomial distribution. Since Sr = L1 + . . . Lr, whereeach Lj has mean 1p . It is shown in Example 4.8.1 that VarSr = rVarL1 = r1pp , ESr = r.p22.7 The Poisson distributiona limit of binomial distributionsk!By denition, the Poisson probability distribution with parameter  > 0 is the one with pmffor k  0. In particular, 0! is dened to equal one, so p0 = e. The next threepk = ekterms of the pmf are p1 = e, p2 = 26 e. The Poisson distributionarises frequently in practice, because it is a good approximation for a binomial distribution withparameters n and p, when n is very large, p is very small, and  = np. Some examples in whichsuch binomial distributions occur are:2 e, and p3 = 346CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLES Radio active emissions in a xed time interval: n is the number of uranium atoms in arock sample, and p is the probability that any particular one of those atoms emits a particlein a one minute period. Incoming phone calls in a xed time interval: n is the number of people with cellphones within the access region of one base station, and p is the probability that a given suchperson will make a call within the next minute. Misspelled words in a document: n is the number of words in a document and p is theprobability that a given word is misspelled.Binomial d