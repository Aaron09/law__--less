st k trials are zeros. SoPL > k = 1  pkfor k  0.2.8The random variable L is said to have the geometric distribution with parameter p. The fact thatthe sum of the probabilities is one,cid:881  pk1p = 1,k=1p . For example, if p = 0.01, EL = 100.is a consequence of taking x = 1  p in the formula 1.5 for the sum of a geometric series.By dierentiating each side of 1.5, setting x = 1  p, and rearranging, we nd that EL =k=1 kpLk = 1Another, more elegant way to nd EL is to condition on the outcome of the rst trial. If theoutcome of the rst trial is one, then L is one. If the outcome of the rst trial is zero, then L iscid:80one plus the number of additional trials until there is a trial with outcome one, which we call cid:101L.Therefore, EL = p 1 + 1 pE1 +cid:101L However, L andcid:101L have the same distribution, because theyare both equal to the number of trials needed until the outcome of a trial is one. So EL = Ecid:101L,and the above equation becomes EL = 1 + 1  pEL, from which it follows that EL = 1p .The variance of L can be found similarly. We could dierentiate each side of 1.5 twice, setx = 1  p, and rearrange. Here we take the alternative approach, just described for nding themean. By the same reasoning as before,EL2 = p + 1  pE1 +cid:101L2 or EL2 = p + 1  pE1 + L2.Expanding out, using the linearity of expectation, yieldsEL2 = p + 1  p1 + 2EL + EL2.p2 . The standard deviation of L is L =cid:112VarL =Solving for EL2, using the fact EL = 11pp , yields EL2 = 2pp2 . Therefore, VarL = EL2EL2 =1pp.It is worth remembering that if p is very small, the mean EL = 1p is very large, and thestandard deviation is nearly as large as the mean just smaller by the factor1  p.Example 2.5.1 Suppose a fair die is repeatedly rolled until each of the numbers one through sixshows at least once. What is the mean number of rolls?Solution. The total number of rolls, R, can be expressed as R = R1+. . .+R6, where for 1  i  6,Ri is the number of rolls made after i  1 distinct numbers have shown, up to and including theroll such that the ith distinct number shows. For example, if the sequence of numbers showing is2, 4, 2, 3, 4, 4, 3, 5, 3, 5, 4, 4, 6, 2, 3, 3, 4, 1, insert a vertical bar just after each roll that shows a newdistinct number to get 2|4|2, 3|4, 4, 3, 5|3, 5, 4, 4, 6|2, 3, 3, 4, 1|. Then Ri is the number of numbers in2.6. BERNOULLI PROCESS AND THE NEGATIVE BINOMIAL DISTRIBUTION43the ith part of the sequence, or, for this example, R1 = R2 = 1, R3 = 2, R4 = 4, R5 = R6 = 5.After i  1 numbers have shown, the probability each subsequent roll is distinct from those i  1numbers is 6i+1. Therefore,ERi = 6. Therefore, Ri has the geometric distribution with parameter 6i+1666i+1 . Hence,cid:18 11cid:19ER = ER1 +  + ER6 =66+65+64+63+62+61= 6+12+13+14+15+16This is a special case of the coupon collector problem, with n = 6 coupon types. In general, if thereare n coupon types, the expected number of coupons needed until at least one coupon of each typeis obtained, is ncid:0 11 + 12 +  + 1ncid:1  n lnn.Memoryless property of geometric distribution Suppose L has the geometric distributionwith parameter p. By the denition of conditional probability and 2.8, for n  0 and k  0 :P L > k + n|L > n ==PL > k + n, L > nPL > nPL > k + nPL > n1  pk+n1  pn== 1  pk = PL > k.That is, P L > k + n|L > n = PL > k, which is called the memoryless property in discretetime. Think of this from the perspective of an observer waiting to see something, such that thetotal waiting time for the observer is L time units, where L has a geometric distribution. Thememoryless property means that given the observer has not nished waiting after n time units, theconditional probability that the observer will still be waiting after k additional time units, is equalto the unconditional probability that the observer will still be waiting after k time units from thebeginning.2.6 Bernoulli process and the negative binomial distributionRecall that a random variable has the Bernoulli distribution with parameter p if it is equal to onewith probability p and to zero otherwise. A Bernoulli process is an innite sequence, X1, X2, . . . ,of Bernoulli random variables, all with the same parameter p, and independent of each other.Therefore, for example, PX5 = 1, X6 = 1, X7 = 0, X12 = 1 = p31  p. The kth random variableXk indicates the random outcome of the kth trial in an innite sequence of trials. For any  inthe underlying probability space, the Bernoulli process has a corresponding realized value Xkfor each time k, and that function of time is called the sample path of the Bernoulli process foroutcome . A sample path of a Bernoulli process is illustrated in Figure 2.6. The gure indicates44CHAPTER 2. DISCRETE-TYPE RANDOM VARIABLESFigure 2.6: Depiction of a sample path of a Bernoulli process.some additional random variables associated with a Bernoulli process, described next.Let L1 be the number of trials needed until the outcome of a trial is one. As seen in Section2.5, L1 has the geome