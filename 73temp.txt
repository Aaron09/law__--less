!2 e1+2 kek!pj1  pkj21kjjj!k  j!cid:19cid:18kwhere  = 1 + 2, and p = 1 . In the last step we used the fact that the sum over the binomialpmf with parameters k and p is one. Thus, we see again that X + Y has the Poisson distributionwith parameter 1 + 2.4.5. DISTRIBUTION OF SUMS OF RANDOM VARIABLES181Example 4.5.3 Suppose X and Y represent the numbers showing for rolls of two fair dice. Thus,each is uniformly distributed over the set 1, 2, 3, 4, 5, 6 and they are independent. The convolutionformula for the pmf of S = X + Y is an instance of the fact that the convolution of two identicalrectangle functions results in a triangle shaped function. See Fig. 4.13.Figure 4.13: The pmf for the sum of the numbers showing for rolls of two fair dice.4.5.2 Sums of jointly continuous-type random variablesSuppose S = X + Y where X and Y are jointly continuous-type. We will express the pdf fS interms of the joint pdf, fX,Y . The method will be to rst nd the CDF of S and then dierentiateit to get the pdf. For any c  R, the event S  c is the same as the event that the random pointX, Y  in the plane falls into the shaded region of Figure 4.14. The shaded region can be integratedFigure 4.14: Shaded region for computation of FSc, where S = X + Y.over by integrating over all u, and for each u xed, integrate over v from  to c  u, socid:90 cid:18cid:90 cucid:19FSc = PS  c =fX,Y u, vdvdu.=1/61  2   3  4  5  6p1/61  2   3  4  5  6p1/6p2  3  4  5  6 7  8   9  10 11 12XYS*uvu+v=c182CHAPTER 4. JOINTLY DISTRIBUTED RANDOM VARIABLESTherefore,fSc ==dFSccid:90 dccid:90 cid:18cid:90 cuddc=cid:19fX,Y u, vdvdufX,Y u, c  udu.4.18The integral in 4.18 can be viewed as the integral of fX,Y over the line u + v = c shown in Figure4.14. This is an integral form of the law of total probability, because in order for X + Y = c, itis necessary that there is some value u such that X = u and Y = c  u. The integral in 4.18integrates and integration is a type of summation over all possible values of u.If X and Y are independent, so that fX,Y u, v = fX ufY v, then 4.18 becomescid:90 fSc =fX ufY c  udu.4.19which, by the denition of the convolution operation , meansfS = fX  fYif S = X + Y , where X, Y are independent.Note the strong similarity between 4.16 and 4.17, derived for sums of integer-valued randomvariables, and 4.18 and 4.19, derived for sums of continuous-type random variables.Example 4.5.4 Suppose X and Y are independent, with each being uniformly distributed overthe interval 0, 1. Find the pdf of S = X + Y.Solution: We have fS = fX  fY , and we will use Figure 4.15 to help work out the integral in4.19. As shown, the graph of the function fY c  u is a rectangle over the interval c  1, c.Figure 4.15: Calculating the convolution of two rectangle functions.To check this, note that if u = c then fY c  u = fY 0, and as u decreases from c to c-1, c  uincreases from zero to c, so fY c  u = 1 for this range of u. The product fX ufY c  u is equalto one on 0, 1  c  1, c and is equal to zero elsewhere. As shown in Figure 4.15, if 0 < c  1,then the overlap is the interval 0, c, and therefore fX  fY c = c. If 1 < c < 2, the overlap is theYc!1cu0f   c!uf   uX1c!10cuf   uXf   c!uY14.5. DISTRIBUTION OF SUMS OF RANDOM VARIABLES183interval c  1, 1 which has length 2  c, and therefore fX  fY c = 2  c. Otherwise, the value ofthe convolution is zero. Summarizing, c0 < c  12  c 1 < c  20else.fSc =so the graph of fS has the triangular shape shown in Figure 4.16.Figure 4.16: The convolution of two identical rectangle functions.Example 4.5.5 Suppose X and Y are independent, with X having the N 0, 2Y having the N 0, 22 distribution. Find the pdf of X + Y.1 distribution andSolution:cid:90 fX+Y c = fX  fY c =fX ufY c  uducid:90 cid:90 ===fX ufY c  udu1cid:90 211212 u222e11 cu2222 due22 cu222 u2221e2 du.The integrand in 4.20 is equal to eAu2+2Bu+C/2, where A = 1But by completing the square,21cid:341cid:1122/Acid:35cid:114 2AeAu2+2Bu+C/2 = u+B/A22/AeeB2/2AC/2.4.214.20+ 122, B =  c22, and C = c222.and the quantity in square brackets in 4.21 is a normal pdf that integrates to one, yielding theidentity:cid:90 eAu2+2Bu+C/2du =eB2/2AC/2.cid:114 2A110c2f   cS184CHAPTER 4. JOINTLY DISTRIBUTED RANDOM VARIABLESTherefore,fX+Y c =12 c2e22 ,1 + 2where 2 = 22. That is, the sum of two independent, mean zero Gaussian random variables isagain Gaussian, and the variance of the sum, 2, is equal to the sum of the variances. The resultcan be extended to the case that X1 and X2 have nonzero means 1 and 2. In that case, the sumis again Gaussian, with mean  = 1 + 2 and variance 2 = 21 + 22.The above derivation is somewhat tedious. There are two more elegant but more advancedways to show that the convolution of two Gaussian pdfs is again a Gaussian pdf. 1 One wayis to use Fourier transformsconvolution of signals is equivalent to multiplication of their Fouriertransforms in the Fourier domain. The Fourier transform of the N 0, 2 pdf is exp22f 2/2,so the result is equivalent to the fact:exp212f 2/2 ex