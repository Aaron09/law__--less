unconstrained estimator gZ of Y based on Z with the minimum MSE, andnd the resulting MSE.4.41. Estimating the third power of a jointly Gaussian random variableSee how parts a and b below combine to yield the answer to part c.a Suppose Z =  + W where W has the N 0, 2 distribution. Express EZ3 in terms of and 2. Note that Z has the N , 2 distribution, and you are nding an expressionfor the third moment of such a random variable.b Suppose X and Y are jointly Gaussian such that X and Y are each standard normal,and the correlation coecient between X and Y is . Describe the marginal distributionof Y given X = u.c Under the same assumptions as b, express EY 3|X = u in terms of  and u.4.42. Joint empirical distribution of ECE 313 scoresThe scatterplot below shows 205 points, ui, vi, where ui is the score on exam two, and vi isthe score on the nal exam, for the ith student in ECE313 in a recent semester. The empiricalmean and standard deviation for exam two are X = 67 and X = 19, the empirical meanand standard deviation for the nal exam are Y = 152 and Y = 35, and the empiricalcorrelation coecient computed using a spreadsheet function is  = 0.71. Visual inspectionof the data suggests it is reasonable to assume that the joint distribution of the two scoresis jointly normal. Let X, Y  be jointly normal random variables with the above parametervalues.4.13. PROBLEMS235a Find EY |X = u as a function of u.b Describe in words the conditional distribution of Y given X = u.236CHAPTER 4. JOINTLY DISTRIBUTED RANDOM VARIABLESChapter 5Wrap-upThe topics in these notes are listed in both the table of contents and the index. This chapter brieysummarizes the material, while highlighting some of the connections among the topics.The probability axioms allow for a mathematical basis for modeling real-world systems withuncertainty, and allow for both discrete-type and continuous-type random variables. Countingproblems naturally arise for calculating probabilities when all outcomes are equally likely, and arecurring idea for counting the total number of ways something can be done is to do it sequentially,such as in, There are n1 choices for the rst ball, and for each choice of the rst ball, there aren2 ways to choose the second ball, and so on. Working with basic probabilities includes workingwith Karnaugh maps, de Morgans laws, and denitions of conditional probabilities and mutualindependence of two or more events. Our intuition can be strengthened and many calculationsmade by appealing to the law of total probability and the denition of conditional probability. Inparticular, we sometimes look back, conditioning on what happened at the end of some scenario,and ask what is the conditional probability that the observation happened in a particular wayusing Bayes rule. Binomial coecients form a link between counting and the binomial probabilitydistribution.A small number of key discrete-type and continuous-type distributions arise again and againin applications. Knowing the form of the CDFs, pdfs, or pmfs, and formulas for the means andvariances, and why each distribution arises frequently in nature and applications, can thus lead toecient modeling and problem solving. There are relationships among the key distributions. Forexample, the binomial distribution generalizes the Bernoulli, and the Poisson distribution is thelarge n, small p limit of the Bernoulli distribution with np = . The exponential distribution isthe continuous time version of the geometric distribution; both are memoryless. The exponentialdistribution is the limit of scaled geometric distributions, and the Gaussian or normal distribution,by the central limit theorem, is the limit of standardized sums of large numbers of independent,identically distributed random variables.The following important concepts apply to both discrete-type random variables and continuous-type random variables: Independence of random variables237238CHAPTER 5. WRAP-UP Marginals and conditionals Functions of one or more random variables, the two or three step procedure to nd theirdistributions, and LOTUS to nd their means EX, VarX, EXY , CovX, Y , X,Y , X , and relationships among these. Binary hypothesis testing ML rule, MAP rule as likelihood ratio tests Maximum likelihood parameter estimation The minimum MSE estimators of Y :  = EY , LX = cid:98EY |X, and gX = EY |X. Markov, Chebychev, and Schwarz inequalities The Chebychev inequality can be used forcondence intervals; the Schwarz inequality implies correlation coecients are between oneand minus one. Law of large numbers and central limit theoremPoisson random processes arise as limits of scaled Bernoulli random processes. Discussion ofthese processes together entails the Bernoulli, binomial, geometric, negative geometric, exponential,Poisson, and Erlang distributions.Reliability in these notes is discussed largely in discrete settingssuch as the outage probabilityfor an s  t network. Failure rate functions for random variables are discussed funconstrained estimator gZ of Y based on Z with the minimum MSE, andnd the resulting MSE.4.41. Estimating the third power of a jointly Gaussian random variableSee how parts a and b below combine to yield the answer to part c.a Suppose Z =  + W where W has the N 0, 2 distribution. Express EZ3 in terms of and 2. Note that Z has the N , 2 distribution, and you are nding an expressionfor the third moment of such a random variable.b Suppose X and Y are jointly Gaussian such that X and Y are each standard normal,and the correlation coecient between X and Y is . Describe the marginal distributionof Y given X = u.c Under the same assumptions as b, express EY 3|X = u in terms of  and u.4.42. Joint empirical distribution of ECE 313 scoresThe scatterplot below shows 205 points, ui, vi, where ui is the score on exam two, and vi isthe score on the nal exam, for the ith student in ECE313 in a recent semester. The empiricalmean and standard deviation for exam two are X = 67 and X = 19, the empirical meanand standard deviation for the nal exam are Y = 152 and Y = 35, and the empiricalcorrelation coecient computed using a spreadsheet function is  = 0.71. Visual inspectionof the data suggests it is reasonable to assume that the joint distribution of the two scoresis jointly normal. Let X, Y  be jointly normal random variables with the above parametervalues.4.13. PROBLEMS235a Find EY |X = u as a function of u.b Describe in words the conditional distribution of Y given X = u.236CHAPTER 4. JOINTLY DISTRIBUTED RANDOM VARIABLESChapter 5Wrap-upThe topics in these notes are listed in both the table of contents and the index. This chapter brieysummarizes the material, while highlighting some of the connections among the topics.The probability axioms allow for a mathematical basis for modeling real-world systems withuncertainty, and allow for both discrete-type and continuous-type random variables. Countingproblems naturally arise for calculating probabilities when all outcomes are equally likely, and arecurring idea for counting the total number of ways something can be done is to do it sequentially,such as in, There are n1 choices for the rst ball, and for each choice of the rst ball, there aren2 ways to choose the second ball, and so on. Working with basic probabilities includes workingwith Karnaugh maps, de Morgans laws, and denitions of conditional probabilities and mutualindependence of two or more events. Our intuition can be strengthened and many calculationsmade by appealing to the law of total probability and the denition of conditional probability. Inparticular, we sometimes look back, conditioning on what happened at the end of some scenario,and ask what is the conditional probability that the observation happened in a particular wayusing Bayes rule. Binomial coecients form a link between counting and the binomial probabilitydistribution.A small number of key discrete-type and continuous-type distributions arise again and againin applications. Knowing the form of the CDFs, pdfs, or pmfs, and formulas for the means andvariances, and why each distribution arises frequently in nature and applications, can thus lead toecient modeling and problem solving. There are relationships among the key distributions. Forexample, the binomial distribution generalizes the Bernoulli, and the Poisson distribution is thelarge n, small p limit of the Bernoulli distribution with np = . The exponential distribution isthe continuous time version of the geometric distribution; both are memoryless. The exponentialdistribution is the limit of scaled geometric distributions, and the Gaussian or normal distribution,by the central limit theorem, is the limit of standardized sums of large numbers of independent,identically distributed random variables.The following important concepts apply to both discrete-type random variables and continuous-type random variables: Independence of random variables237238CHAPTER 5. WRAP-UP Marginals and conditionals Functions of one or more random variables, the two or three step procedure to nd theirdistributions, and LOTUS to nd their means EX, VarX, EXY , CovX, Y , X,Y , X , and relationships among these. Binary hypothesis testing ML rule, MAP rule as likelihood ratio tests Maximum likelihood parameter estimation The minimum MSE estimators of Y :  = EY , LX = cid:98EY |X, and gX = EY |X. Markov, Chebychev, and Schwarz inequalities The Chebychev inequality can be used forcondence intervals; the Schwarz inequality implies correlation coecients are between oneand minus one. Law of large numbers and central limit theoremPoisson random processes arise as limits of scaled Bernoulli random processes. Discussion ofthese processes together entails the Bernoulli, binomial, geometric, negative geometric, exponential,Poisson, and Erlang distributions.Reliability in these notes is discussed largely in discrete settingssuch as the outage probabilityfor an s  t network. Failure rate functions for random variables are discussed f