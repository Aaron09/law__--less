  terms yields 6CovX, Y  = 6CovX, Y , or CovX, Y  = 0.Hence, X and Y are uncorrelated.b No. For example, suppose X is any random variable with positive variance and PX =Y  = 1. Then VarX = VarY  but CovX, Y  = VarX cid:54= 0.c Yes, because VarX + Y  = VarX + VarY  + 2CovX, Y , so the given statement isequivalent to VarX + VarY  + 2CovX, Y  = VarX + VarY , or CovX, Y  = 0.d No. For example, suppose PX = Y = 1 = PX = Y = 1 = 0.5. Then X 2 andY 2 are both equal to one with probability one, so CovX 2, Y 2 = Cov1, 1 = 0, butCovX, Y  = EXY   EXEY  = 1  0  0 = 1 cid:54= 0.4.20. Variances and covariances of sumsa Cov3X + 2, 5Y  1 = Cov3X, 5Y  = 15CovX, Y .bCov2X + 1, X + 5Y  1 = Cov2X, X + 5Y  = Cov2X, X + Cov2X, 5Y = 2CovX, X + 10CovX, Y  = 2VarX + 10CovX, Y cCov2X + 3Z, Y + 2Z = Cov2X, Y  + Cov2X + 2Z + Cov3Z, Y  + Cov3Z, 2Z= 2CovX, Y  + 4CovX, Z + 3CovZ, Y  + 6CovZ, Z= 2CovX, Y  + 6VarZ4.22. Signal to noise ratio with correlated observations6.6. SOLUTIONS TO EVEN NUMBERED PROBLEMS277a In general, for S = X1+X22.cid:20 X1 + X2cid:212VarX1 + X2422ES = S = E= 2S =SN RS =2 + CovX1, X2=22 + 2CovX1, X24=2 + CovX1, X22Thus, if X1 and X2 are uncorrelated, SN RS = 222 = 2SN RX . Thus, averaging im-proves the SN R by a factor equal to the number of observations being averaged, if theobservations are uncorrelated.b Since CovX1, X2 = 2X1,X2, the formula above for SN RS is equivalent toSN RS =2221 + X1X2.Setting SN RS equal to 1.5 2c SN RS   as X1X2  1.2 yields XY = 13 .4.24. Linear minimum MSE estimation from uncorrelated observationsa The MSE can be written as EY  bX1  cX2  a2, which is the same as the MSEfor estimation of Y  bX1  cX2 by the constant a. The optimal choice of a is EY bX1  cX2 = EY . Substituting a = EY , the MSE satisesMSE = VarY  bX1  cX2= CovY  bX1  cX2, Y  bX1  cX2= CovY, Y  + b2CovX1, X1  2bCovY, X1 + c2CovX2, X2  2cCovY, X2= VarY  +cid:0b2VarX1  2bCovY, X1cid:1 +cid:0c2VarX2  2cCovY, X2cid:1 . 6.2The MSE is quadratic in b and c and the minimizers are easily found to be b = CovY,X1VarX1and c = CovY,X2VarX2. Thus, LX1, X2 = EY  + CovY,X1VarX1b Substituting the values of b and c found into 6.2 yieldsX1 + CovY,X2VarX2X2.MSE = VarY   CovY, X12VarX1 CovY, X22VarX2.4.26. Whats new? or the innovations methoda CovX1, X2  hX1 = CovX1, X2  hVarX1 = 0.5  h, so h = 0.5. Thus, cid:102X2 =X2  0.5X1.bVarcid:101X2 = CovX2  0.5X1, X2  0.5X1CovY, cid:101X2 = CovY, X2  0.5X1= VarX2  20.5CovX1, X2 + 0.52VarX1= 1  0.5 + 0.25 = 0.75.c a = EY  = 0, b = CovY,X1VarX1= CovY, X2  0.5CovY, X1= 0.8  0.50.8 = 0.4= 0.8, and c = CovY,cid:101X2Varcid:101X2 CovY, cid:101X22Varcid:101X2= 0.40.75 , andMSE = VarY   CovY, X12VarX1= 1  0.64  0.420.75= 0.1466 . . . .d The estimator is L = 0.8X1 + 0.40.75 X2  0.5X1 = 0.40.75 X1 + X2.4.28. Simple estimation problemsa The range of possible values of X is the interval 0, 1. By inspection or using thedenition of conditional density, if 0  u  1, we see that given X = u, the conditionaldistribution of Y is the uniform distribution over the interval 0, u. Therefore, EY 2|X =u =cid:82 uof u, it is also equal to cid:98EY |X = u. That is, cid:98EY |X = u = uout using the formula for cid:98EY |X = u as well.b By the same observation used in part a, EY |X = u = uu v2dv = u23 .2 . Since this is a linear function2 . This result can be worked10LLN, CLT, and joint Gaussian distribution Sections 4.10  4.114.30. Law of Large Numbers and Central Limit Theorema From LLN, we havePPcid:26cid:12cid:12cid:12cid:12 Sncid:26cid:12cid:12cid:12cid:12 Snnncid:27cid:27cid:12cid:12cid:12cid:12  0.01Xcid:12cid:12cid:12cid:12 < 0.01X X X2Xn1042X2X 1 n1042Xwhere X = 1+2+3+4+5+6substituting for X and 26= 3.5 and 2X = 1+4+9+16+25+366X in the equation below, 3.52 = 2.9167. Thus,1 2Xn1042X 0.95gives n  47620. If we were to plug in the cruder approximation 2.92 for 2get n  47674, which for most purposes is close enough.X we would6.6. SOLUTIONS TO EVEN NUMBERED PROBLEMSb ESn = 3.5n, VarSn = 2.9167n, and the standard deviation of Sn is 1.7078P|Sn  3.5n|  0.035n = P279n.cid:26|Sn  3.5n|cid:18 0.035n1.7078n1.7078n 1  2Q 0.035nn1.7078cid:19cid:27From the normal tables, Qx = 0.025 for x = 1.96. Thus, n  cid:1001.961.7078/0.0352cid:101 =9147 is sucient. We would get a slightly dierent answer if we took a cruder approxi-mation of X .4.32. Marathon blackjacka The expected net gain is 1000$1000.0029 = $290b The net gain, in dollars, is the sum of the gains for the 1000 games, S = X1 +  + Xn,where each Xi has mean 1000.0029 = 0.29 and standard deviation 1001.141 =114. As already mentioned, S has mean 10000.29 = 290, and its standard devia-tion is 1141000 = 3605. By the Gaussian approximation backed by the central limittheorem,PS > 0 = Pccid:26 S + 290cid:26 S + 29036053605>2903605 Qcid:27cid:27cid:19cid:18 290cid:18 129036053605= 0.4679cid:19= 0.3602PS > 1000 = P>12903605 Qd Replacing 1000 by a general integer n, we havecid:26 S + 0.29n114ncid:27 Qcid:18 0.29ncid:19114n>0.29nn114PS > 0 = PSince Q0.253 = 0.4, we solve 0.29nn =That is a lot   terms yields 6CovX, Y  = 6CovX, Y , or CovX, Y  = 0.Hence, X and Y are uncorrelated.b No. For example, suppose X is any random variable with positive variance and PX =Y  = 1. Then VarX = VarY  but CovX, Y  = VarX cid:54= 0.c Yes, because VarX + Y  = VarX + VarY  + 2CovX, Y , so the given statement isequivalent to VarX + VarY  + 2CovX, Y  = VarX + VarY , or CovX, Y  = 0.d No. For example, suppose PX = Y = 1 = PX = Y = 1 = 0.5. Then X 2 andY 2 are both equal to one with probability one, so CovX 2, Y 2 = Cov1, 1 = 0, butCovX, Y  = EXY   EXEY  = 1  0  0 = 1 cid:54= 0.4.20. Variances and covariances of sumsa Cov3X + 2, 5Y  1 = Cov3X, 5Y  = 15CovX, Y .bCov2X + 1, X + 5Y  1 = Cov2X, X + 5Y  = Cov2X, X + Cov2X, 5Y = 2CovX, X + 10CovX, Y  = 2VarX + 10CovX, Y cCov2X + 3Z, Y + 2Z = Cov2X, Y  + Cov2X + 2Z + Cov3Z, Y  + Cov3Z, 2Z= 2CovX, Y  + 4CovX, Z + 3CovZ, Y  + 6CovZ, Z= 2CovX, Y  + 6VarZ4.22. Signal to noise ratio with correlated observations6.6. SOLUTIONS TO EVEN NUMBERED PROBLEMS277a In general, for S = X1+X22.cid:20 X1 + X2cid:212VarX1 + X2422ES = S = E= 2S =SN RS =2 + CovX1, X2=22 + 2CovX1, X24=2 + CovX1, X22Thus, if X1 and X2 are uncorrelated, SN RS = 222 = 2SN RX . Thus, averaging im-proves the SN R by a factor equal to the number of observations being averaged, if theobservations are uncorrelated.b Since CovX1, X2 = 2X1,X2, the formula above for SN RS is equivalent toSN RS =2221 + X1X2.Setting SN RS equal to 1.5 2c SN RS   as X1X2  1.2 yields XY = 13 .4.24. Linear minimum MSE estimation from uncorrelated observationsa The MSE can be written as EY  bX1  cX2  a2, which is the same as the MSEfor estimation of Y  bX1  cX2 by the constant a. The optimal choice of a is EY bX1  cX2 = EY . Substituting a = EY , the MSE satisesMSE = VarY  bX1  cX2= CovY  bX1  cX2, Y  bX1  cX2= CovY, Y  + b2CovX1, X1  2bCovY, X1 + c2CovX2, X2  2cCovY, X2= VarY  +cid:0b2VarX1  2bCovY, X1cid:1 +cid:0c2VarX2  2cCovY, X2cid:1 . 6.2The MSE is quadratic in b and c and the minimizers are easily found to be b = CovY,X1VarX1and c = CovY,X2VarX2. Thus, LX1, X2 = EY  + CovY,X1VarX1b Substituting the values of b and c found into 6.2 yieldsX1 + CovY,X2VarX2X2.MSE = VarY   CovY, X12VarX1 CovY, X22VarX2.4.26. Whats new? or the innovations methoda CovX1, X2  hX1 = CovX1, X2  hVarX1 = 0.5  h, so h = 0.5. Thus, cid:102X2 =X2  0.5X1.bVarcid:101X2 = CovX2  0.5X1, X2  0.5X1CovY, cid:101X2 = CovY, X2  0.5X1= VarX2  20.5CovX1, X2 + 0.52VarX1= 1  0.5 + 0.25 = 0.75.c a = EY  = 0, b = CovY,X1VarX1= CovY, X2  0.5CovY, X1= 0.8  0.50.8 = 0.4= 0.8, and c = CovY,cid:101X2Varcid:101X2 CovY, cid:101X22Varcid:101X2= 0.40.75 , andMSE = VarY   CovY, X12VarX1= 1  0.64  0.420.75= 0.1466 . . . .d The estimator is L = 0.8X1 + 0.40.75 X2  0.5X1 = 0.40.75 X1 + X2.4.28. Simple estimation problemsa The range of possible values of X is the interval 0, 1. By inspection or using thedenition of conditional density, if 0  u  1, we see that given X = u, the conditionaldistribution of Y is the uniform distribution over the interval 0, u. Therefore, EY 2|X =u =cid:82 uof u, it is also equal to cid:98EY |X = u. That is, cid:98EY |X = u = uout using the formula for cid:98EY |X = u as well.b By the same observation used in part a, EY |X = u = uu v2dv = u23 .2 . Since this is a linear function2 . This result can be worked10LLN, CLT, and joint Gaussian distribution Sections 4.10  4.114.30. Law of Large Numbers and Central Limit Theorema From LLN, we havePPcid:26cid:12cid:12cid:12cid:12 Sncid:26cid:12cid:12cid:12cid:12 Snnncid:27cid:27cid:12cid:12cid:12cid:12  0.01Xcid:12cid:12cid:12cid:12 < 0.01X X X2Xn1042X2X 1 n1042Xwhere X = 1+2+3+4+5+6substituting for X and 26= 3.5 and 2X = 1+4+9+16+25+366X in the equation below, 3.52 = 2.9167. Thus,1 2Xn1042X 0.95gives n  47620. If we were to plug in the cruder approximation 2.92 for 2get n  47674, which for most purposes is close enough.X we would6.6. SOLUTIONS TO EVEN NUMBERED PROBLEMSb ESn = 3.5n, VarSn = 2.9167n, and the standard deviation of Sn is 1.7078P|Sn  3.5n|  0.035n = P279n.cid:26|Sn  3.5n|cid:18 0.035n1.7078n1.7078n 1  2Q 0.035nn1.7078cid:19cid:27From the normal tables, Qx = 0.025 for x = 1.96. Thus, n  cid:1001.961.7078/0.0352cid:101 =9147 is sucient. We would get a slightly dierent answer if we took a cruder approxi-mation of X .4.32. Marathon blackjacka The expected net gain is 1000$1000.0029 = $290b The net gain, in dollars, is the sum of the gains for the 1000 games, S = X1 +  + Xn,where each Xi has mean 1000.0029 = 0.29 and standard deviation 1001.141 =114. As already mentioned, S has mean 10000.29 = 290, and its standard devia-tion is 1141000 = 3605. By the Gaussian approximation backed by the central limittheorem,PS > 0 = Pccid:26 S + 290cid:26 S + 29036053605>2903605 Qcid:27cid:27cid:19cid:18 290cid:18 129036053605= 0.4679cid:19= 0.3602PS > 1000 = P>12903605 Qd Replacing 1000 by a general integer n, we havecid:26 S + 0.29n114ncid:27 Qcid:18 0.29ncid:19114n>0.29nn114PS > 0 = PSince Q0.253 = 0.4, we solve 0.29nn =That is a lot 