n 2  1.182, which is a circle centered at the origin with radius approximately 1.18. Since allthe bivariate normal pdfs are obtained from fW,Z by linear scaling and translation, the half-peaklevel set of a general bivariate normal pdf completely determines the pdf. The half-peak level setfor the general bivariate normal fX,Y given by 4.40 isu, v :cid:16 uXcid:172Xcid:16 vYY+cid:16 uXcid:17cid:16 vYcid:17XYcid:172  21  2 ,= 2 ln 2  1.182which is an ellipse. The space of ellipses in the plane is ve dimensionaltwo coordinates specify thecenter of an ellipse, two numbers give the lengths of the major and minor axes, and a nal numbergives the angle of the major axis from the horizontal. This gives another way to parameterize theset of bivariate normal pdfs using ve parameters.4.11.2 Key properties of the bivariate normal distributionProposition 4.11.2 Suppose X and Y have the bivariate normal pdf with parameters X , Y , X , Y ,and . Thena X has the N X , 2X  distribution, and Y has the N Y , 2Y  distribution.b Any linear combination of the form aX + bY is a Gaussian random variable i.e., X and Yare jointly Gaussian.c  is the correlation coecient between X and Y i.e. X,Y = .d X and Y are independent if and only if  = 0.e For estimation of Y from X, LX = gX. Equivalently, EY |X = cid:98EY |X. That is, thef  The conditional distribution of Y given X = u is N cid:98EY |X = u, 2best unconstrained estimator gX is linear.for cid:98EY |X, given by 4.37 or 4.38.e , where 2e is the MSEProof. It suces to prove the proposition in case X = Y = 0 and 2Y = 1, because theseparameters simply involve centering and scaling of X and Y separately, or, equivalently, translationand scaling of the joint pdf parallel to the u-axis or parallel to the v-axis. Such centering and scalingof X and Y separately does not change the correlation coecient, as shown in Section 4.8.X = 2The joint pdf in this case can be written as the product of two factors, as follows:12cid:1121  2cid:20 1cid:18exp2exp u22cid:19cid:18 u2 + v2  2uvcid:19cid:21cid:341cid:11221  221  2fX,Y u, v ==cid:19cid:35cid:18 v  u221  2.4.41exp4.11. JOINT GAUSSIAN DISTRIBUTION219The rst factor is a function of u alone, and is the standard normal pdf. The second factor, as afunction of v for u xed, is a Gaussian pdf with mean u and variance 1  2. In particular, theintegral of the second factor with respect to v is one. Therefore, the rst factor is the marginal pdfof X and the second factor is the conditional pdf of Y given X = u :cid:19cid:181cid:11221  212exp u22expfX u =fY |X v|u =cid:18 v  u221  2cid:19.4.42Thus, X is a standard normal random variable. By symmetry, Y is also a standard normal randomvariable. This proves a.cid:1 by a matrix A if det A cid:54= 0. Given a and b, we can select c and d so thatcid:1 has a bivariatecid:1 has detA = ad  bc cid:54= 0. Then the random vector Acid:0Xmultiplication of cid:0Xthe matrix A =cid:0aThe class of bivariate normal pdfs is preserved under linear transformations corresponding toYbdcnormal pdf, so by part a already proven, both of its coordinates are Gaussian random variables.In particular, its rst coordinate, aX + bY, is a Gaussian random variable. This proves b.By 4.42, given X = u, the conditional distribution of Y is Gaussian with mean u and variance1  2. Therefore, gu = EY |X = u = u. Since X and Y are both standard i.e. they havemean zero and variance one, X,Y = EXY , soYX,Y = EXY  ==cid:18cid:90 cid:19uvfX ufY |X v|udvduvfY |X v|udvduufX u= u2fX udu = .cid:90 cid:90 cid:90 cid:90 This proves c.If  cid:54= 0 then X,Y cid:54= 0 so that X and Y are not independent. If  = 0 then fX,Y factors intoBy 4.36, Lu = u. Therefore, Lu = gu, as claimed, proving e. By 4.37, the MSEthe product of two single-variable normal pdfs, so X and Y are independent. This proves d.for using L is 2e = 1  2, so f follows from 4.42.Example 4.11.3 Let X and Y be jointly Gaussian random variables with mean zero, 2Y = 2, and CovX, Y  = 1. Find PX + 2Y  1.2X = 5,Solution: Let Z = X + 2Y. Then Z is a linear combination of jointly Gaussian random variables,so Z itself is a Gaussian random variable. Also, EZ = EX + 2EY  = 0 and2Z = CovX + 2Y, X + 2Y  = CovX, X + CovX, 2Y  + Cov2Y, X + Cov2Y, 2Y Thus, PX + 2Y  1 = PZ  1 = Pcid:8 ZX + 4CovX, Y  + 42= 2Y = 5  4 + 8 = 9.cid:9 = Qcid:0 1cid:1 = 1   133  133   0.3694.220CHAPTER 4. JOINTLY DISTRIBUTED RANDOM VARIABLESExample 4.11.4 Let X and Y be jointly Gaussian random variables with mean zero, varianceone, and CovX, Y  = . Find EY 2|X, the best estimator of Y 2 given X. Hint: X and Y 2 arenot jointly Gaussian. But you know the conditional distribution of Y given X = u and can use itto nd the conditional second moment of Y given X = u.Solution: Recall the fact that EZ2 = EZ2 + VarZ for a random variable Z. The ideais to apply the fact to the conditional distribution of Y given X. Given X = u, the conditionaldistribution of Y is Gaussian with mean u and variance 12. Thus, EY 2|X = u = u2+12.Therefore, EY 2|X = X2 + 1n 2  1.182, which is a circle centered at the origin with radius approximately 1.18. Since allthe bivariate normal pdfs are obtained from fW,Z by linear scaling and translation, the half-peaklevel set of a general bivariate normal pdf completely determines the pdf. The half-peak level setfor the general bivariate normal fX,Y given by 4.40 isu, v :cid:16 uXcid:172Xcid:16 vYY+cid:16 uXcid:17cid:16 vYcid:17XYcid:172  21  2 ,= 2 ln 2  1.182which is an ellipse. The space of ellipses in the plane is ve dimensionaltwo coordinates specify thecenter of an ellipse, two numbers give the lengths of the major and minor axes, and a nal numbergives the angle of the major axis from the horizontal. This gives another way to parameterize theset of bivariate normal pdfs using ve parameters.4.11.2 Key properties of the bivariate normal distributionProposition 4.11.2 Suppose X and Y have the bivariate normal pdf with parameters X , Y , X , Y ,and . Thena X has the N X , 2X  distribution, and Y has the N Y , 2Y  distribution.b Any linear combination of the form aX + bY is a Gaussian random variable i.e., X and Yare jointly Gaussian.c  is the correlation coecient between X and Y i.e. X,Y = .d X and Y are independent if and only if  = 0.e For estimation of Y from X, LX = gX. Equivalently, EY |X = cid:98EY |X. That is, thef  The conditional distribution of Y given X = u is N cid:98EY |X = u, 2best unconstrained estimator gX is linear.for cid:98EY |X, given by 4.37 or 4.38.e , where 2e is the MSEProof. It suces to prove the proposition in case X = Y = 0 and 2Y = 1, because theseparameters simply involve centering and scaling of X and Y separately, or, equivalently, translationand scaling of the joint pdf parallel to the u-axis or parallel to the v-axis. Such centering and scalingof X and Y separately does not change the correlation coecient, as shown in Section 4.8.X = 2The joint pdf in this case can be written as the product of two factors, as follows:12cid:1121  2cid:20 1cid:18exp2exp u22cid:19cid:18 u2 + v2  2uvcid:19cid:21cid:341cid:11221  221  2fX,Y u, v ==cid:19cid:35cid:18 v  u221  2.4.41exp4.11. JOINT GAUSSIAN DISTRIBUTION219The rst factor is a function of u alone, and is the standard normal pdf. The second factor, as afunction of v for u xed, is a Gaussian pdf with mean u and variance 1  2. In particular, theintegral of the second factor with respect to v is one. Therefore, the rst factor is the marginal pdfof X and the second factor is the conditional pdf of Y given X = u :cid:19cid:181cid:11221  212exp u22expfX u =fY |X v|u =cid:18 v  u221  2cid:19.4.42Thus, X is a standard normal random variable. By symmetry, Y is also a standard normal randomvariable. This proves a.cid:1 by a matrix A if det A cid:54= 0. Given a and b, we can select c and d so thatcid:1 has a bivariatecid:1 has detA = ad  bc cid:54= 0. Then the random vector Acid:0Xmultiplication of cid:0Xthe matrix A =cid:0aThe class of bivariate normal pdfs is preserved under linear transformations corresponding toYbdcnormal pdf, so by part a already proven, both of its coordinates are Gaussian random variables.In particular, its rst coordinate, aX + bY, is a Gaussian random variable. This proves b.By 4.42, given X = u, the conditional distribution of Y is Gaussian with mean u and variance1  2. Therefore, gu = EY |X = u = u. Since X and Y are both standard i.e. they havemean zero and variance one, X,Y = EXY , soYX,Y = EXY  ==cid:18cid:90 cid:19uvfX ufY |X v|udvduvfY |X v|udvduufX u= u2fX udu = .cid:90 cid:90 cid:90 cid:90 This proves c.If  cid:54= 0 then X,Y cid:54= 0 so that X and Y are not independent. If  = 0 then fX,Y factors intoBy 4.36, Lu = u. Therefore, Lu = gu, as claimed, proving e. By 4.37, the MSEthe product of two single-variable normal pdfs, so X and Y are independent. This proves d.for using L is 2e = 1  2, so f follows from 4.42.Example 4.11.3 Let X and Y be jointly Gaussian random variables with mean zero, 2Y = 2, and CovX, Y  = 1. Find PX + 2Y  1.2X = 5,Solution: Let Z = X + 2Y. Then Z is a linear combination of jointly Gaussian random variables,so Z itself is a Gaussian random variable. Also, EZ = EX + 2EY  = 0 and2Z = CovX + 2Y, X + 2Y  = CovX, X + CovX, 2Y  + Cov2Y, X + Cov2Y, 2Y Thus, PX + 2Y  1 = PZ  1 = Pcid:8 ZX + 4CovX, Y  + 42= 2Y = 5  4 + 8 = 9.cid:9 = Qcid:0 1cid:1 = 1   133  133   0.3694.220CHAPTER 4. JOINTLY DISTRIBUTED RANDOM VARIABLESExample 4.11.4 Let X and Y be jointly Gaussian random variables with mean zero, varianceone, and CovX, Y  = . Find EY 2|X, the best estimator of Y 2 given X. Hint: X and Y 2 arenot jointly Gaussian. But you know the conditional distribution of Y given X = u and can use itto nd the conditional second moment of Y given X = u.Solution: Recall the fact that EZ2 = EZ2 + VarZ for a random variable Z. The ideais to apply the fact to the conditional distribution of Y given X. Given X = u, the conditionaldistribution of Y is Gaussian with mean u and variance 12. Thus, EY 2|X = u = u2+12.Therefore, EY 2|X = X2 + 1